# -*- coding: utf-8 -*-
"""kohya_config_webui.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/WSH032/kohya-config-webui/blob/main/kohya_config_webui.ipynb

| ![visitors](https://visitor-badge.glitch.me/badge?page_id=wsh.kohya_config_webui) | [![GitHub Repo stars](https://img.shields.io/github/stars/WSH032/kohya-config-webui?style=social)](https://github.com/WSH032/kohya-config-webui)</a> |

#A WebUI for making config files used by kohya_sd_script

Created by [WSH](https://space.bilibili.com/8417436)
"""


"""
ã€Šç»´æŠ¤æŒ‡å—ã€‹ï¼š
å¦‚æœä½ æƒ³ä¸ºwebuiä¸‰ä¸ªé€‰é¡¹å¡ä¸­ä»»æ„ä¸€ä¸ªé€‰é¡¹å¡æ·»åŠ ä¸€ä¸ªæ–°çš„ç»„ä»¶ï¼Œå¹¶ä»¥å…¶å€¼æŒ‡å®štomlæ–‡ä»¶ç›¸åº”çš„å‚æ•°
1ã€
å»webuiéƒ¨åˆ†æ·»åŠ ç›¸åº”çš„ç»„ä»¶ä»£ç ï¼Œå¹¶ç»™æ–°çš„ç»„ä»¶å‘½åã€‚
**å¦‚ï¼šåœ¨commonå‚æ•°éƒ¨åˆ†æ·»åŠ  new_param = gr.Number(value=3)
2ã€
åœ¨ç›¸åº”çš„parameter_dict_key_listä¸­åŠ ä¸Šè¯¥ç»„ä»¶å˜é‡åå­—ã€‚
**å¯¹äºä¸Šé¢çš„ä¾‹å­ï¼š parameter_dict_key_list.append("new_param")
è¿è¡Œã€åœ¨webuiä¸­ç¡®è®¤å‚æ•°åï¼Œç›¸åº”çš„ç»„ä»¶å€¼ä¼šè¢«å‚¨å­˜åœ¨ç›¸åº”çš„å…¨å±€å˜é‡parameter_dictä¸­
**å¯¹äºä¸Šé¢çš„ä¾‹å­common_parameter_dict.get("new_param")    #ouput=3
3ã€
æ‰¾åˆ°parameter2toml()å‡½æ•°, ç¡®è®¤ä½ è¦å†™å…¥tomlæ–‡ä»¶çš„ä½ç½®ï¼Œæ¯”å¦‚è¯´ä½ æƒ³åœ¨[model_arguments]é”®ä¸‹é¢æ·»åŠ ä¸€ä¸ª new_param=3
é‚£ä¹ˆè¯·ç”¨model_arguments.update( "new_param":all.get("new_param")  )
æ³¨æ„è¿™é‡Œç”¨çš„æ˜¯allè¿™ä¸ªå­—å…¸ï¼Œå› ä¸ºåœ¨parameter2toml()ä¸€å¼€å§‹å°±ä¼šæŠŠä¸‰ä¸ªå…¨å±€å‚æ•°å­—å…¸åˆæˆä¸€ä¸ªallå­—å…¸
4ã€
å®Œæˆï¼Œæ£€æŸ¥ç”Ÿæˆçš„tomlæ˜¯å¦æ­£ç¡®
"""

#@title å‡½æ•°éƒ¨åˆ†


import os
import toml
import warnings
import gradio as gr

#ç”¨äºå‚¨å­˜é€‚ä¸‰ä¸ªé€‰é¡¹å¡ä¸­è¾“å…¥ç»„ä»¶çš„åå­—
common_parameter_dict_key_list=[]
sample_parameter_dict_key_list=[]
plus_parameter_dict_key_list=[]
all_parameter_dict_key_list=[]  #åé¢ä¼šæœ‰ä¸€æ¬¡all_parameter_dict_key_list = common_parameter_dict_key_list + sample_parameter_dict_key_list + plus_parameter_dict_key_list
    
#ç”¨äºå‚¨å­˜æ‰€æœ‰ç¡®è®¤çš„ç»„ä»¶å€¼ï¼Œå¦‚è®­ç»ƒé›†åœ°å€
common_parameter_dict=({})
sample_parameter_dict=({})
plus_parameter_dict=({})

common_confirm_flag = False   #å¿…é¡»è¦ç¡®è®¤å¸¸è§„å‚æ•°ä¸€æ¬¡æ‰å…è®¸å†™å…¥toml

#ç”¨äºç¡®å®šæ¯ä¸ªé€‰é¡¹å¡ä¸­æŒ‰é”®çš„æ•°é‡ï¼Œæ–¹ä¾¿all_parameter_get
parameter_len_dict={"common":0, "sample":0, "plus":0}

#å›¾æ ‡å¸¸é‡
random_symbol = '\U0001f3b2\ufe0f'  # ğŸ²ï¸
reuse_symbol = '\u267b\ufe0f'  # â™»ï¸
paste_symbol = '\u2199\ufe0f'  # â†™
refresh_symbol = '\U0001f504'  # ğŸ”„
save_style_symbol = '\U0001f4be'  # ğŸ’¾
apply_style_symbol = '\U0001f4cb'  # ğŸ“‹
clear_prompt_symbol = '\U0001f5d1\ufe0f'  # ğŸ—‘ï¸
extra_networks_symbol = '\U0001F3B4'  # ğŸ´
switch_values_symbol = '\U000021C5' # â‡…
folder_symbol = '\U0001f4c2'  # ğŸ“‚


def check_len_and_2dict(args, parameter_len_dict_value, parameter_dict_key_list, func_name=""):
    """ ä¸‰ä¸ªparameter_get()ä¼šæŠŠgradioç»„ä»¶çš„å€¼ä¼ è¿›æ¥ï¼Œæ£€æŸ¥ä¼ å…¥å€¼æ•°é‡å’Œparameter_len_dict_valueæ˜¯å¦ç›¸ç­‰ """
    """ ç›¸ç­‰åˆ™è¿”å›ä»¥parameter_dict_key_listä¸­å­—ç¬¦ä¸²åšä¸ºkeyåå­—çš„å­—å…¸ """
    """ ä¸ç›¸ç­‰å°±ç»™ä¸€ä¸ªwanring """
    if len(args) != parameter_len_dict_value:
        warnings.warn(f"ä¼ å…¥{func_name}çš„å‚æ•°é•¿åº¦ä¸åŒ¹é…", UserWarning)
    if len(parameter_dict_key_list) != parameter_len_dict_value:
        warnings.warn(f" {func_name}å†…éƒ¨å­—å…¸èµ‹å€¼å…³é”®å­—åˆ—è¡¨çš„é•¿åº¦ä¸åŒ¹é…", UserWarning)
    parameter_dict = dict(zip(parameter_dict_key_list, args))
    return parameter_dict


""" ä¸‹é¢ä¸‰ä¸ªå‡½æ•°ä¼šè·å–å„è‡ªé€‰é¡¹å¡ä¸­çš„è¾“å…¥å€¼ï¼Œç„¶åä½¿ç”¨å°†å…¶è½¬ä¸ºå­—å…¸å¹¶èµ‹å€¼ç»™å„è‡ªçš„å…¨å±€å˜é‡parameter_dict """
""" æœ€åè¿”å›webuiç›¸åº”çš„è¾“å‡ºä¿¡æ¯ """
def common_parameter_get(*args):
    global common_parameter_dict, common_confirm_flag
    common_confirm_flag = True    #å¿…é¡»è¦ç¡®è®¤å¸¸è§„å‚æ•°ä¸€æ¬¡æ‰å…è®¸å†™å…¥toml
    common_parameter_dict = check_len_and_2dict(args, parameter_len_dict["common"], common_parameter_dict_key_list, func_name="common_parameter_get")
    common_parameter_toml = toml.dumps(common_parameter_dict)
    common_parameter_title = "åŸºç¡€å‚æ•°é…ç½®ç¡®è®¤"
    return common_parameter_toml,  common_parameter_title

def sample_parameter_get(*args):
    global sample_parameter_dict
    sample_parameter_dict = check_len_and_2dict(args, parameter_len_dict["sample"], sample_parameter_dict_key_list, func_name="sample_parameter_get")
    sample_parameter_toml = toml.dumps(sample_parameter_dict)
    sample_parameter_title = "é‡‡æ ·é…ç½®ç¡®è®¤"
    return sample_parameter_toml,  sample_parameter_title


def plus_parameter_get(*args):
    global plus_parameter_dict
    plus_parameter_dict = check_len_and_2dict(args, parameter_len_dict["plus"], plus_parameter_dict_key_list, func_name="plus_parameter_get")
    plus_parameter_toml = toml.dumps(plus_parameter_dict)
    plus_parameter_title = "è¿›é˜¶å‚æ•°é…ç½®ç¡®è®¤"
    return plus_parameter_toml,  plus_parameter_title


"""  è°ƒç”¨ä¸Šé¢ä¸Šä¸ªå‡½æ•°æ¥ç¡®è®¤å…¨éƒ¨å‚æ•°å€¼ï¼Œå¹¶èµ‹å€¼ç»™ä¸‰ä¸ªå…¨å±€å­—å…¸parameter_dict """
def all_parameter_get(*args):
    if len(args) != sum( parameter_len_dict.values() ):
         warnings.warn(f"ä¼ å…¥all_parameter_getçš„å‚æ•°é•¿åº¦ä¸åŒ¹é…", UserWarning)
    """ é€šè¿‡parameter_len_dictå­—å…¸ä¸­è®°å½•çš„å„ä¸ªé€‰é¡¹å¡è¾“å…¥ç»„ä»¶æ•°é‡æ¥åˆ†é…ä¼ å…¥ä¸‰ä¸ªå­å‡½æ•°çš„å‚æ•° """
    common_parameter_toml,  common_parameter_title = common_parameter_get( *args[ : parameter_len_dict["common"] ] )
    sample_parameter_toml,  sample_parameter_title = sample_parameter_get( *args[ parameter_len_dict["common"] : parameter_len_dict["common"] + parameter_len_dict["sample"] ] )
    plus_parameter_toml,  plus_parameter_title = plus_parameter_get( *args[ -parameter_len_dict["plus"] : ] )
    return common_parameter_toml, sample_parameter_toml, plus_parameter_toml,  "å…¨éƒ¨å‚æ•°ç¡®è®¤"

                      
def save_webui_config(save_webui_config_dir, save_webui_config_name, write_files_dir):
    """ ä¿å­˜å½“å‰å·²ç»ç¡®è®¤ï¼ˆåœ¨ä¸‰ä¸ªå‚æ•°å­—å…¸ä¸­ï¼Œè€Œä¸æ˜¯webuiä¸­ç»„ä»¶å€¼ï¼‰çš„é…ç½®å‚æ•° """
    os.makedirs(save_webui_config_dir, exist_ok=True)
    
    other = {"write_files_dir":write_files_dir}
    param = {**common_parameter_dict, **sample_parameter_dict, **plus_parameter_dict}
    dict = { "other":other, "param":param }

    save_webui_config_path = os.path.join(save_webui_config_dir, save_webui_config_name)
    with open(save_webui_config_path, "w", encoding="utf-8") as f:
        webui_config_str = toml.dumps( dict )
        f.write(webui_config_str)
    return f"ä¿å­˜webuié…ç½®æˆåŠŸï¼Œæ–‡ä»¶åœ¨{save_webui_config_path}"

def read_webui_config_get(read_webui_config_dir):
    """ è¯»å–ç›®å½•ä¸‹ä»¥.tomlç»“å°¾çš„æ–‡ä»¶ï¼Œè¿”å›ä¸€ä¸ªè¯»å–åˆ°çš„æ–‡ä»¶listæ¥æ›´æ–°gradioç»„ä»¶ """
    try:
        files = [f for f in os.listdir(read_webui_config_dir) if f.endswith(".toml") ]
        if files:
            return gr.update( choices=files,value=files[0] )
        else:
            return gr.update( choices=[],value="æ²¡æœ‰æ‰¾åˆ°webuié…ç½®æ–‡ä»¶" )
    except Exception as e:
        return gr.update( choices=[], value=f"é”™è¯¯çš„æ–‡ä»¶å¤¹è·¯å¾„:{e}" )
    
def read_webui_config(read_webui_config_dir, read_webui_config_name, write_files_dir, *args):
    """ è¯»å–é¢„å…ˆä¿å­˜çš„configæ–‡ä»¶ï¼Œæ¥æ›´æ–°webuiç•Œé¢(æ³¨æ„ï¼Œä¸æ›´æ–°å‚æ•°å­—å…¸ï¼Œéœ€è¦ç”¨æˆ·æ‰‹åŠ¨ç¡®è®¤) """
    
    dir_change_flag = False         #è¯»å–å®Œä¿å­˜çš„configæ–‡ä»¶åä¼šä¿®æ”¹å†™å…¥æ–‡ä»¶å¤¹è¿™ä¸€ç»„ä»¶ï¼Œè¿™é‡Œä¼šåˆ¤æ–­æ˜¯å¦ä¿®æ”¹ï¼Œå¦‚ä¿®æ”¹ç»™webuiä¸€ä¸ªæç¤º
    #æ£€æŸ¥ä¼ å…¥çš„æ›´æ–°ç»„ä»¶æ•°é‡æ˜¯å¦å’Œwebuiä¸­ä¸€è‡´
    param_len = sum( parameter_len_dict.values() )
    if len(args) != param_len:
        warnings.warn(f"ä¼ å…¥read_webui_configçš„*argsé•¿åº¦ä¸åŒ¹é…", UserWarning)

    read_webui_config_path = os.path.join(read_webui_config_dir, read_webui_config_name)
    #èƒ½æ‰“å¼€å°±æ­£å¸¸æ“ä½œ
    try:
        with open(read_webui_config_path, "r", encoding="utf-8") as f:
            config_dict = toml.loads( f.read() )
        
        #èƒ½è¯»åˆ°["other"].["write_files_dir"]å°±æ”¹ï¼Œè¯»ä¸åˆ°å°±ç”¨åŸå†™å…¥åœ°å€
        try:
            if config_dict["other"]["write_files_dir"] != write_files_dir:
                write_files_dir = config_dict["other"]["write_files_dir"]
                dir_change_flag = True
        except KeyError:
            pass
        
        param_dict_key_list = list( config_dict.get("param",{}).keys() )
        #æ‰¾å‡ºå…±æœ‰çš„keyè¿›è¡Œèµ‹å€¼ï¼Œéå…±æœ‰çš„æŠ¥é”™
        both_key = set(all_parameter_dict_key_list) & set(param_dict_key_list)
        parameter_unique_key = set(all_parameter_dict_key_list) - set(both_key)
        config_unique_key = set(param_dict_key_list) - set(both_key)
        #èµ‹å€¼
        count = 0
        if both_key:
            args = list(args)
            for key in both_key:
                index = all_parameter_dict_key_list.index(key)
                args[ index ] = config_dict["param"][key]
                count += 1
            args = tuple(args)
        read_done = f"\nè¯»å–å®Œæˆ,WebUIä¸­å…±æœ‰{param_len}é¡¹å‚æ•°,æ›´æ–°äº†å…¶ä¸­{count}é¡¹\n" + f"å†™å…¥æ–‡ä»¶å¤¹å‘ç”Ÿæ”¹å˜:{write_files_dir}" if dir_change_flag else ""
        config_warning = f"\nwebui-configæ–‡ä»¶ä¸­ä»¥ä¸‹å‚æ•°å¯èƒ½å·²ç»å¤±æ•ˆæˆ–é”™è¯¯ï¼š\n{config_unique_key}\n" if config_unique_key else ""
        parameter_warning = f"\nWebUIä¸­ä»¥ä¸‹å‚æ•°åœ¨webui-configæ–‡ä»¶ä¸­æœªæ‰¾åˆ°ï¼Œä¸å‘ç”Ÿä¿®æ”¹ï¼š\n{parameter_unique_key}\n" if parameter_unique_key else ""
        str = read_done + config_warning + parameter_warning
        return  str, write_files_dir, *args

    #æ‰“ä¸å¼€å°±è¿”å›åŸå€¼
    except FileNotFoundError:
        return "æ–‡ä»¶æˆ–ç›®å½•ä¸å­˜åœ¨", write_files_dir, *args
    except PermissionError:
        return "æ²¡æœ‰æƒé™è®¿é—®æ–‡ä»¶æˆ–ç›®å½•", write_files_dir, *args
    except OSError as e:
        return f"something wrongï¼š{e}", write_files_dir, *args
    
    

def model_get(model_dir):
    """ è¯»å–æ–‡ä»¶å¤¹ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶ """
    try:
        files = [f for f in os.listdir(model_dir) if os.path.isfile(os.path.join(model_dir, f))]
        if files:
            return gr.update( choices=files,value=files[0] )
        else:
            return gr.update( choices=[],value="æ²¡æœ‰æ‰¾åˆ°æ¨¡å‹" )
    except Exception as e:
        return gr.update( choices=[], value=f"é”™è¯¯çš„æ–‡ä»¶å¤¹è·¯å¾„:{e}" )


def write_files(write_files_dir):
    """ ç”¨å‚æ•°å­—å…¸ç”Ÿæˆä¸ºkohyaè®­ç»ƒè„šæœ¬è¦æ±‚çš„tomlæ ¼å¼æ–‡ä»¶ """

    if not common_confirm_flag:
        return "å¿…é¡»è¦ç¡®è®¤å¸¸è§„å‚æ•°ä¸€æ¬¡æ‰å…è®¸å†™å…¥toml"

    write_files_dir = write_files_dir if write_files_dir else os.path.join(os.getcwd(), "kohya_config")
    os.makedirs(write_files_dir, exist_ok=True)
    config_file_toml_path = os.path.join(write_files_dir, "config_file.toml")
    sample_prompts_txt_path = os.path.join(write_files_dir, "sample_prompts.txt")

    all = {**common_parameter_dict, **sample_parameter_dict, **plus_parameter_dict}

    def parameter2toml():

        #ç”Ÿæˆconfig_file.tomlçš„å­—å…¸

        #model_argumentséƒ¨åˆ†
        model_arguments = { key: all.get(key) for key in ["v2", "v_parameterization"] }
        """ ç”Ÿæˆåº•æ¨¡è·¯å¾„ """
        base_model_path = os.path.join( all.get("base_model_dir"), all.get("base_model_name") )
        model_arguments.update( {"pretrained_model_name_or_path": base_model_path} )
        """ ç”Ÿæˆvaeè·¯å¾„ """
        if all.get("use_vae"):
            vae_model_path = os.path.join( all.get("vae_model_dir"), all.get("vae_model_name") )
            model_arguments.update( {"vae": vae_model_path} )

        #additional_network_argumentséƒ¨åˆ†
        additional_network_arguments = { key: all.get(key) for key in ["unet_lr", "text_encoder_lr", "network_dim",\
                                            "network_alpha", "network_train_unet_only",\
                                            "network_train_text_encoder_only"] }
        """ ç”Ÿæˆå¦‚network_module = "locon.locon_kohya" """
        #["LoRA-LierLa", "LoRA-C3Lier", "LoCon_Lycoris", "LoHa_Lycoris", "DyLoRa-LierLa", "DyLoRa-C3Lier"]
        #ä¸»è¦è´Ÿè´£network_moduleçš„å‚æ•°ç”Ÿæˆ
        def network_module_param(train_method):
            conv_dim = all.get("conv_dim") if train_method != "DyLoRa-C3Lier" else all.get("network_dim")
            conv_alpha = all.get("conv_alpha")
            algo = "lora" if train_method == "LoCon_Lycoris" else "loha"
            unit = all.get("unit")
            if train_method in ["LoRA-LierLa", "LoRA-C3Lier"]:
                network_module = "networks.lora"
                if train_method == "LoRA-C3Lier":
                    network_module_args = [f"conv_dim={conv_dim}", f"conv_alpha={conv_alpha}"]
                else:
                    network_module_args = []
            elif train_method in ["LoCon_Lycoris", "LoHa_Lycoris"]:
                network_module = "lycoris.kohya"
                network_module_args = [f"conv_dim={conv_dim}", f"conv_alpha={conv_alpha}", f"algo={algo}"]
            elif train_method in ["DyLoRa-LierLa", "DyLoRa-C3Lier"]:
                network_module = "networks.dylora"
                if train_method == "DyLoRa-C3Lier":
                    network_module_args = [f"conv_dim={conv_dim}", f"conv_alpha={conv_alpha}", f"unit={unit}"]
                else:
                    network_module_args = [f"unit={unit}"]
            else: 
                warnings.warn(f"è®­ç»ƒæ–¹æ³•å‚æ•°ç”Ÿæˆå‡ºé”™", UserWarning)
            return network_module, network_module_args
        network_module, network_module_args = network_module_param( all.get("train_method") )
        #æ›´å¤šnetwork_argséƒ¨åˆ†ï¼ˆä¸»è¦ä¸ºåˆ†å±‚è®­ç»ƒï¼‰
        network_lr_weight_args = [ f"{name}={all.get(name)}" for name in ["up_lr_weight", "mid_lr_weight", "down_lr_weight"] if all.get(name) ]

        def network_block_param(train_method):
            lst = ["block_dims", "block_alphas", "conv_block_dims", "conv_block_alphas"]
            if train_method == "LoRA-LierLa":
                return [ f"{name}={all.get(name)}" for name in lst[0:1] if all.get(name) ]
            if train_method in ["LoRA-C3Lier", "LoCon_Lycoris", "LoHa_Lycoris"]:
                return [ f"{name}={all.get(name)}" for name in lst if all.get(name) ]
            else:
                return []
        network_block_args = network_block_param( all.get("train_method") )
        

        network_args = []
        network_args.extend(network_module_args)
        network_args.extend(network_lr_weight_args)
        network_args.extend(network_block_args)

        additional_network_arguments.update( { "network_module":network_module } )
        additional_network_arguments.update( {"network_args":network_args} )          

        #optimizer_argumentséƒ¨åˆ†
        optimizer_arguments = { key: all.get(key) for key in ["optimizer_type", "lr_scheduler", "lr_warmup_steps"] }
        """åªæœ‰ä½™å¼¦é‡å¯è°ƒåº¦å™¨æŒ‡å®šé‡å¯æ¬¡æ•°"""
        if all.get("lr_scheduler") == "cosine_with_restarts":
            optimizer_arguments.update( {"lr_restart_cycles":all.get("lr_restart_cycles")} )
        """å­¦ä¹ ç‡lræŒ‡å®š=unet_lr"""
        optimizer_arguments.update( {"learning_rate":all.get("unet_lr")} )
            #optimizer_argsï¼ˆå¾…æ·»åŠ ï¼‰

        #dataset_argumentséƒ¨åˆ†
        dataset_arguments = { key: all.get(key) for key in ["cache_latents", "shuffle_caption", "enable_bucket"] }
        
        #training_argumentséƒ¨åˆ†
        training_arguments = { key: all.get(key) for key in ["batch_size", "noise_offset", "keep_tokens",\
                                      "min_bucket_reso", "max_bucket_reso",\
                                      "caption_extension", "max_token_length", "seed",\
                                      "xformers", "lowram"]
        }
        """min_snr_gammaå¤§äºé›¶æ‰ç”Ÿæ•ˆ"""
        if all.get("min_snr_gamma") > 0:
            training_arguments.update( { "min_snr_gamma":all.get("min_snr_gamma") } )
        """ æœ€å¤§è®­ç»ƒæ—¶é—´ """
        training_arguments.update( { all.get("max_train_method"):all.get("max_train_value") } )
        """ è®­ç»ƒåˆ†è¾¨ç‡ """
        training_arguments.update( { "resolution":f"{all.get('width')},{all.get('height')}" } )
        """ å¦‚æœv2å¼€å¯ï¼Œåˆ™ä¸æŒ‡å®šclip_skip """
        if not all.get("v2"):
            training_arguments.update( { "clip_skip":all.get("clip_skip") } )
        """ é‡è®­ç»ƒæ¨¡å— """
        if all.get("use_retrain") == "model":
            training_arguments.update( { "network_weights":all.get("retrain_dir") } )
        elif all.get("use_retrain") == "state":
            training_arguments.update( { "resume":all.get("retrain_dir") } )
        """  è®­ç»ƒç²¾åº¦ã€ä¿å­˜ç²¾åº¦ """
        training_arguments.update( { "mixed_precision":"fp16" } )
        training_arguments.update( { "save_precision":"fp16" } )
        


        #sample_prompt_argumentséƒ¨åˆ†ï¼ˆé‡‡æ ·é—´éš”ï¼Œé‡‡æ ·æ–‡ä»¶åœ°å€å¾…æ·»åŠ ï¼‰
        sample_prompt_arguments = { key: all.get(key) for key in ["sample_sampler"] }
        if all.get("sample_every_n_type"):    #å¦‚æœé‡‡æ ·éƒ¨åˆ†æ²¡ç¡®è®¤è¿‡ä¸€æ¬¡ï¼Œä¼šå‡ºç°all.get("sample_every_n_type")=None:Noneçš„å­—å…¸é€ æˆæŠ¥é”™
            sample_prompt_arguments.update( {all.get("sample_every_n_type"):all.get("sample_every_n_type_value")} )

        #dreambooth_argumentséƒ¨åˆ†
        dreambooth_arguments = { key: all.get(key) for key in ["train_data_dir", "reg_data_dir", "prior_loss_weight"] }

        #saving_argumentséƒ¨åˆ†
        saving_arguments = { key: all.get(key) for key in ["output_name", "save_every_n_epochs", "save_n_epoch_ratio",\
                                      "save_last_n_epochs", "save_state", "save_model_as" ]
        }
        """åœ¨è¾“å‡ºæ–‡ä»¶å¤¹output_diråé¢åŠ ä¸Šoutput_name"""
        output_dir = os.path.join( all.get("output_dir"), all.get("output_name") )
        saving_arguments.update( {"output_dir":output_dir } )
        """ æŒ‡å®šlogè¾“å‡ºç›®å½•ä¸outputç›¸åŒ """
        saving_arguments.update( { "logging_dir":os.path.join( output_dir, "logs" ) } )
        """ æŒ‡å®šlogå‰ç¼€å’Œè¾“å‡ºåå­—ç›¸åŒ """
        saving_arguments.update( { "log_prefix":all.get("output_name") } )
        """ å¯ç”¨wandb"""
            #å†³å®šlogè®°å½•æ–¹å¼
        if all.get("use_wandb"):
            saving_arguments.update( { "log_with":"all" } )
        else:
            saving_arguments.update( { "log_with":"tensorboard" } )
            #api_keyå’Œlog_tracker_nameçš„æŒ‡å®š
        if all.get("wandb_api_key"):
            saving_arguments.update( { "wandb_api_key":all.get("wandb_api_key") } )
        if all.get("log_tracker_name"):
            saving_arguments.update( { "log_tracker_name":all.get("log_tracker_name") } )

                                      
        ##åˆæˆæ€»å­—å…¸
        toml_dict = {"model_arguments":model_arguments,
               "additional_network_arguments":additional_network_arguments,
               "optimizer_arguments":optimizer_arguments,
               "dataset_arguments":dataset_arguments,
               "training_arguments":training_arguments,
               "sample_prompt_arguments":sample_prompt_arguments,
               "dreambooth_arguments":dreambooth_arguments,
               "saving_arguments":saving_arguments,
        }
        toml_str = toml.dumps(toml_dict)
        return toml_str
    def sample_parameter2txt():
        #key_list = ["prompt", "negative", "sample_width", "sample_height", "sample_scale", "sample_steps", "sample_seed"]
        
        #å¦‚æœé‡‡æ ·éƒ¨åˆ†æ²¡ç¡®è®¤è¿‡ï¼Œè¿™ä¸ªå€¼=Noneï¼›æˆ–è€…æ²¡å†™ä»»ä½•promptï¼›å°±ç›´æ¥é€€å‡º,è¿”å›ä¸€ä¸ªç©ºå­—ç¬¦ä¸²
        if not all.get("prompt"):
            return ""
        #å…è®¸åˆ†è¡Œ
        prompt = all.get("prompt").replace("\n", "")
        negative = all.get("negative").replace("\n", "")
        #ç”Ÿæˆé‡‡æ ·æ–‡ä»¶str
        sample_str = f"""{prompt}  \
--n {negative}  \
--w {all.get("sample_width")}  \
--h {all.get("sample_height")}  \
--l {all.get("sample_scale")}  \
--s {all.get("sample_steps")}  \
{f"--d {all.get('sample_seed')}" if all.get('sample_seed') > 0 else ""}"""
        return sample_str

    def write(content, path):
        with open(path, "w", encoding="utf-8") as f:
            f.write(content)

    write(parameter2toml(), config_file_toml_path)
    write(sample_parameter2txt(), sample_prompts_txt_path)
    write_files_title = f"å†™å…¥æˆåŠŸ, è®­ç»ƒé…ç½®æ–‡ä»¶åœ¨{config_file_toml_path}, é‡‡æ ·å‚æ•°æ–‡ä»¶åœ¨{sample_prompts_txt_path}"
    return write_files_title

#@title WebUIéƒ¨åˆ†


with gr.Blocks() as demo:
    with gr.Accordion("ä¿å­˜ã€è¯»å–\nwebuié…ç½®", open=False):
        save_read_webui_config_title = gr.Markdown("ä¿å­˜æˆ–è¯»å–")
        with gr.Row():
            save_webui_config_button = gr.Button("ä¿å­˜")
        with gr.Row():
            save_webui_config_dir = gr.Textbox(lines=1, label="ä¿å­˜ç›®å½•", value=os.path.join(os.getcwd(),"kohya_config_webui_save") )
            save_webui_config_name = gr.Textbox(lines=1, label="ä¿å­˜åå­—ï¼ˆä»¥tomlä¸ºæ‰©å±•åï¼Œå¦åˆ™ä¸ä¼šè¢«è¯»å–ï¼‰", value="kohya_config_webui_save.toml" )
        with gr.Row():
            read_webui_config_get_button = gr.Button(refresh_symbol)
            read_webui_config_button = gr.Button("è¯»å–")
        with gr.Row():
            read_webui_config_dir = gr.Textbox(lines=1, label="è¯»å–ç›®å½•", value=os.path.join(os.getcwd(),"kohya_config_webui_save") )  
            read_webui_config_name = gr.Dropdown(choices=[], label="è¯»å–æ–‡ä»¶", value="" )          
    with gr.Row():
        write_files_button = gr.Button("ç”Ÿæˆtomlå‚æ•°ä¸é‡‡æ ·é…ç½®æ–‡ä»¶")
        all_parameter_get_button = gr.Button("å…¨éƒ¨å‚æ•°ç¡®è®¤")
        write_files_dir = gr.Textbox( lines=1, label="å†™å…¥æ–‡ä»¶å¤¹", placeholder="ä¸€èˆ¬å¡«kohya_scriptç›®å½•ï¼Œç•™ç©ºå°±é»˜è®¤æ ¹ç›®å½•ä¸‹çš„kohya_configæ–‡ä»¶å¤¹", value="" )
    write_files_title = gr.Markdown("ç”Ÿæˆé€‚ç”¨äºkohya/train_network.pyçš„é…ç½®æ–‡ä»¶")
    with gr.Tabs():
        with gr.TabItem("åŸºç¡€å‚æ•°"):
            common_parameter_get_button = gr.Button("ç¡®å®š")
            common_parameter_title = gr.Markdown("")
            with gr.Accordion("å½“å‰åŸºç¡€å‚æ•°é…ç½®", open=False):
                common_parameter_toml = gr.Textbox(label="tomlå½¢å¼", placeholder="åŸºç¡€å‚æ•°", value="")
            with gr.Row():
                train_data_dir = gr.Textbox(lines=1, label="train_data_dir", placeholder="è®­ç»ƒé›†è·¯å¾„", value="")
            with gr.Accordion("ä½¿ç”¨æ­£åˆ™åŒ–(å¯é€‰)", open=False):
                with gr.Row():
                    reg_data_dir = gr.Textbox(lines=1, label="reg_data_dir", placeholder="æ­£åˆ™åŒ–é›†è·¯å¾„ï¼ˆå¡«å…¥æ„å‘³ç€å¯ç”¨æ­£åˆ™åŒ–ï¼‰", value="")
                    prior_loss_weight = gr.Slider(0, 1, step=0.01, value=0.3, label="æ­£åˆ™åŒ–æƒé‡")
            with gr.Row():
                base_model_dir = gr.Textbox(label="åº•æ¨¡æ–‡ä»¶å¤¹åœ°å€", placeholder="æ–‡ä»¶å¤¹è·¯å¾„", value="")
                base_model_name = gr.Dropdown(choices=[],label="åº•æ¨¡",value="")
                base_model_get_button = gr.Button(refresh_symbol)
            with gr.Accordion("ä½¿ç”¨vae(å¯é€‰)", open=False):
                with gr.Row():
                    use_vae = gr.Checkbox(label="æ˜¯å¦ä½¿ç”¨vae",value=False)
                with gr.Row():
                    vae_model_dir = gr.Textbox(label="vaeæ–‡ä»¶å¤¹åœ°å€", placeholder="æ–‡ä»¶å¤¹è·¯å¾„", value="")
                    vae_model_name = gr.Dropdown(choices=[],label="vae", value="")
                    vae_model_get_button = gr.Button(refresh_symbol)
            with gr.Row():
                width = gr.Slider(64, 1920, step=64, value=512, label="è®­ç»ƒåˆ†è¾¨ç‡ï¼ˆå®½ï¼‰width")
                height = gr.Slider(64, 1920, step=64, value=512, label="è®­ç»ƒåˆ†è¾¨ç‡ï¼ˆé«˜ï¼‰height")
                batch_size = gr.Slider(1, 24, step=1, value=1, label="batchå¤§å°")
            with gr.Row():
                noise_offset = gr.Slider(0, 1, step=0.01, value=0.05, label="noise_offset")
                keep_tokens = gr.Slider(0, 225, step=1, value=0, label="keep_tokens")
                min_snr_gamma = gr.Slider(0, 100, step=0.1, value=5, label="min_snr_gamma(è®¾ç½®ä¸º0åˆ™ä¸ç”Ÿæ•ˆ)")
            """
            with gr.Row():
                gr.Markdown("repeat * å›¾ç‰‡æ•° = æ¯ä¸ªepochçš„stepsæ•°")
            """
            with gr.Row():
                max_train_method = gr.Dropdown(["max_train_epochs","max_train_steps"], label="ä»¥epochsæˆ–stepsæ¥æŒ‡å®šæœ€å¤§è®­ç»ƒæ—¶é—´", value="max_train_epochs")
                max_train_value = gr.Number(label="æœ€å¤§è®­ç»ƒepochs\stepsæ•°", value=10, precision=0)
            with gr.Accordion("è¾“å‡ºè®¾ç½®", open=True):
                with gr.Row():
                    output_dir = gr.Textbox( label="æ¨¡å‹ã€logæ—¥å¿—è¾“å‡ºåœ°å€ï¼ˆè‡ªè¡Œä¿®æ”¹ï¼‰", placeholder="æ–‡ä»¶å¤¹è·¯å¾„",value=os.path.join(os.getcwd(),"output") )
                    output_name = gr.Textbox(label="è¾“å‡ºæ¨¡å‹åç§°ï¼ˆè‡ªè¡Œä¿®æ”¹ï¼‰", placeholder="åç§°",value="output_name")
                    save_model_as = gr.Dropdown(["safetensors","ckpt","pt"], label="ä¿å­˜æ¨¡å‹æ ¼å¼", value="safetensors")
                with gr.Row():
                    save_every_n_epochs = gr.Slider(1, 499, step=1, value=1, label="æ¯nä¸ªepochä¿å­˜ä¸€æ¬¡")
                    save_n_epoch_ratio = gr.Slider(1, 499, step=1, value=0, label="ç­‰é—´éš”ä¿å­˜nä¸ª(å¦‚ä¸ä¸º0ï¼Œä¼šè¦†ç›–æ¯nä¸ªepochä¿å­˜ä¸€æ¬¡)")
                    save_last_n_epochs = gr.Slider(1, 499, step=1, value=499, label="æœ€å¤šä¿å­˜nä¸ªï¼ˆåé¢çš„å‡ºæ¥å°±ä¼šæŠŠå‰é¢åˆ äº†,ä¼˜å…ˆçº§æœ€é«˜ï¼‰")
                with gr.Row():   
                    save_state = gr.Checkbox(label="ä¿å­˜å­¦ä¹ çŠ¶æ€",value=False)
                with gr.Accordion("å¯ç”¨è¿œç¨‹è®°å½•", open=False):
                        with gr.Row():
                            gr.Markdown( "[ä½ å¯ä»¥åœ¨è¿™é‡Œæ‰¾åˆ°api_key](https://wandb.ai/authorize)")
                        with gr.Row():
                            use_wandb = gr.Checkbox(label="æ˜¯å¦ä½¿ç”¨wandbè¿œç¨‹è®°å½•", value= False)
                            wandb_api_key = gr.Textbox(label="wandb_api_key", placeholder="ç¬¬ä¸€æ¬¡ä½¿ç”¨ï¼Œæˆ–è€…éœ€è¦åˆ‡æ¢æ–°APIçš„æ—¶å€™ï¼Œè¯·å¡«å…¥", value="")
                            log_tracker_name = gr.Textbox(label="log_tracker_nameé¡¹ç›®åç§°", placeholder="ç•™ç©ºåˆ™æŒ‡å®šä¸ºnetwork_train",value="")
            with gr.Row():
                optimizer_type = gr.Dropdown(["AdamW8bit", "Lion", "DAdaptation", "AdamW", "SGDNesterov", "SGDNesterov8bit", "AdaFactor"],\
                                label="optimizer_typeä¼˜åŒ–å™¨ç±»å‹", value="AdamW8bit")
                unet_lr = gr.Number(label="unetå­¦ä¹ ç‡", value=1e-4)
                text_encoder_lr = gr.Number(label="text_encoderå­¦ä¹ ç‡", value=1e-5)
            with gr.Row():
                lr_scheduler = gr.Dropdown(["cosine_with_restarts","cosine","polynomial","linear","constant_with_warmup","constant"],\
                               label="lr_schedulerå­¦ä¹ ç‡è°ƒåº¦å™¨", value="cosine_with_restarts")
                lr_warmup_steps = gr.Number(label="å‡æ¸©æ­¥æ•°", value=0, precision=0)
                lr_restart_cycles = gr.Number(label="é€€ç«é‡å¯æ¬¡æ•°", value=1, precision=0)
            with gr.Row():
                train_method = gr.Dropdown(["LoRA-LierLa", "LoRA-C3Lier",\
                                "LoCon_Lycoris","LoHa_Lycoris",\
                                "DyLoRa-LierLa", "DyLoRa-C3Lier"],\
                                label="train_methodè®­ç»ƒæ–¹æ³•", value="LoRA-LierLa")
                network_dim = gr.Number(label="çº¿æ€§dim", value=32, precision=0)
                network_alpha = gr.Number(label="çº¿æ€§alphaï¼ˆå¯ä»¥ä¸ºå°æ•°ï¼‰", value=16)
            with gr.Accordion("é¢å¤–ç½‘ç»œå‚æ•°(LoRA-C3Lierã€LoConã€LoHaã€DyLoRa-C3Lieréƒ½å±äºå·ç§¯,unitä¸ºDyLoRaä¸“ç”¨)", open=True):
                with gr.Row():
                    with gr.Column():
                        conv_dim = gr.Number(label="å·ç§¯dim", info="ä½¿ç”¨DyLoRa-C3Lieræ—¶ä¼šè¢«è®¾ç½®ä¸ºç­‰äºåŸºç¡€dim", value=8, precision=0)
                    with gr.Column():
                        conv_alpha = gr.Number(label="å·ç§¯alpha", info="å¯ä»¥ä¸ºå°æ•°", value=1)
                    with gr.Column():
                        unit = gr.Number(label="åˆ†å‰²å•ä½unit(æ•´æ•°)", info="ä½¿ç”¨DyLoRaæ—¶ï¼Œè¯·è®©dimä¸ºunitçš„å€æ•°", value=1, precision=0)
            with gr.Row():          
                v2 = gr.Checkbox(label="v2")
                v_parameterization = gr.Checkbox(label="v_parameterization")
                lowram = gr.Checkbox(label="lowram")
                xformers = gr.Checkbox(label="xformers",value=True)
                cache_latents = gr.Checkbox(label="cache_latents",value=True)
                shuffle_caption = gr.Checkbox(label="shuffle_caption",value=True)
                enable_bucket = gr.Checkbox(label="enable_bucket",value=True)
        with gr.TabItem("é‡‡æ ·å‚æ•°"):
            sample_parameter_get_button = gr.Button("ç¡®å®š")
            sample_parameter_title = gr.Markdown("")
            with gr.Accordion("å½“å‰é‡‡æ ·é…ç½®", open=False):
                sample_parameter_toml = gr.Textbox(label="tomlå½¢å¼", placeholder="é‡‡æ ·é…ç½®", value="")
            with gr.Row():
                #enable_sample = gr.Checkbox(label="æ˜¯å¦å¯ç”¨é‡‡æ ·åŠŸèƒ½")
                sample_every_n_type = gr.Dropdown(["sample_every_n_epochs", "sample_every_n_steps"], label="sample_every_n_type", value="sample_every_n_epochs")
                sample_every_n_type_value = gr.Number(label="sample_every_n_type_value", value=1, precision=0)
            with gr.Row():
                sample_sampler = gr.Dropdown(["ddim", "pndm", "lms", "euler", "euler_a", "heun",\
                            "dpm_2", "dpm_2_a", "dpmsolver","dpmsolver++", "dpmsingle",\
                            "k_lms", "k_euler", "k_euler_a", "k_dpm_2", "k_dpm_2_a"],\
                            label="é‡‡æ ·å™¨", value="euler_a")
                sample_seed = gr.Number(label="é‡‡æ ·ç§å­(-1ä¸æ˜¯éšæœºï¼Œå¤§äº0æ‰ç”Ÿæ•ˆ)", value=-1, precision=0)
            with gr.Row():
                sample_width = gr.Slider(64, 1920, step=64, value=512, label="é‡‡æ ·å›¾ç‰‡å®½")
                sample_height = gr.Slider(64, 1920, step=64, value=768, label="é‡‡æ ·å›¾ç‰‡é«˜")
                sample_scale = gr.Slider(1, 30, step=0.5, value=7, label="æç¤ºè¯ç›¸å…³æ€§")
                sample_steps = gr.Slider(1, 150, step=1, value=24, label="é‡‡æ ·è¿­ä»£æ­¥æ•°")
            with gr.Row():
                prompt = gr.Textbox(lines=10, label="prompt", placeholder="æ­£é¢æç¤ºè¯", value="(masterpiece, best quality, hires:1.2), 1girl, solo,")
                default_negative = ("(worst quality, bad quality:1.4), "
                          "lowres, bad anatomy, bad hands, text, error, "
                          "missing fingers, extra digit, fewer digits, "
                          "cropped, worst quality, low quality, normal quality, "
                          "jpeg artifacts,signature, watermark, username, blurry,")
                negative = gr.Textbox(lines=10, label="negative", placeholder="è´Ÿé¢æç¤ºè¯", value=default_negative)
        with gr.TabItem("è¿›é˜¶å‚æ•°"):
            plus_parameter_get_button = gr.Button("ç¡®å®š")
            plus_parameter_title = gr.Markdown("")
            with gr.Accordion("å½“å‰è¿›é˜¶å‚æ•°é…ç½®", open=False):
                plus_parameter_toml = gr.Textbox(label="tomlå½¢å¼", placeholder="è¿›é˜¶å‚æ•°", value="")
            with gr.Row():
                use_retrain = gr.Dropdown(["no","model","state"], label="æ˜¯å¦ä½¿ç”¨é‡è®­ç»ƒ", value="no")
                retrain_dir = gr.Textbox(lines=1, label="é‡è®­ç»ƒè·¯å¾„", placeholder="æ¨¡å‹æˆ–è€…çŠ¶æ€è·¯å¾„", value="")
            with gr.Row():
                min_bucket_reso = gr.Slider(64, 1920, step=64, value=256, label="æœ€ä½æ¡¶åˆ†è¾¨ç‡")
                max_bucket_reso = gr.Slider(64, 1920, step=64, value=1024, label="æœ€é«˜æ¡¶åˆ†è¾¨ç‡")
                clip_skip = gr.Slider(0, 25, step=1, value=2, label="è·³è¿‡å±‚æ•°")
                max_token_length = gr.Slider(75, 225, step=75, value=225, label="è®­ç»ƒæœ€å¤§tokenæ•°")
                caption_extension = gr.Textbox(lines=1, label="æ ‡ç­¾æ–‡ä»¶æ‰©å±•å", placeholder="ä¸€èˆ¬å¡«.txtæˆ–.cap", value=".txt")
                seed = gr.Number(label="ç§å­", value=1337, precision=0)
            with gr.Row():
                network_train_unet_only= gr.Checkbox(label="ä»…è®­ç»ƒunetç½‘ç»œ",value=False)
                network_train_text_encoder_only = gr.Checkbox(label="ä»…è®­ç»ƒtext_encoderç½‘ç»œ",value=False)
            with gr.Accordion("åˆ†å±‚å­¦ä¹ æ¨¡å—", open=True):
                gr.Markdown("å­¦ä¹ ç‡åˆ†å±‚ï¼Œä¸ºä¸åŒå±‚çš„ç»“æ„æŒ‡å®šä¸åŒå­¦ä¹ ç‡å€æ•°ï¼› å¦‚æœæŸä¸€å±‚æƒé‡ä¸º0ï¼Œé‚£è¯¥å±‚ä¸ä¼šè¢«åˆ›å»º")
                with gr.Row():
                    with gr.Column(scale=15):
                        up_lr_weight = gr.Textbox(lines=1, label="ä¸Šå±‚å­¦ä¹ ç‡æƒé‡", placeholder="ç•™ç©ºåˆ™ä¸å¯ç”¨",\
                                      info="12å±‚ï¼Œä¾‹å¦‚1.5,1.5,1.5,1.5,1.0,1.0,1.0,1.0,0.5,0.5,0.5,0.5", value="")
                    with gr.Column(scale=1):
                        mid_lr_weight = gr.Textbox(lines=1, label="ä¸­å±‚å­¦ä¹ ç‡æƒé‡", placeholder="ç•™ç©ºåˆ™ä¸å¯ç”¨",\
                                      info="1å±‚ï¼Œä¾‹å¦‚2.0", value="")
                    with gr.Column(scale=15):
                        down_lr_weight = gr.Textbox(lines=1, label="ä¸‹å±‚å­¦ä¹ ç‡æƒé‡", placeholder="ç•™ç©ºåˆ™ä¸å¯ç”¨",\
                                      info="12å±‚ï¼Œä¾‹å¦‚0.5,0.5,0.5,0.5,1.0,1.0,1.0,1.0,1.5,1.5,1.5,1.5", value="")
                gr.Markdown("dimå’Œalphaåˆ†å±‚ï¼Œä¸ºä¸åŒå±‚çš„ç»“æ„æŒ‡å®šä¸åŒçš„dimå’Œalphaï¼ˆ`DyLoRa`æ— æ³•ä½¿ç”¨ï¼Œå·ç§¯åˆ†å±‚åªæœ‰`LoRa-C3Lierã€LoConã€LoHa`å¯ä»¥ä½¿ç”¨ï¼‰")
                with gr.Row():
                        block_dims = gr.Textbox(lines=1, label="çº¿æ€§dimåˆ†å±‚", placeholder="ç•™ç©ºåˆ™ä¸å¯ç”¨",\
                                      info="25å±‚ï¼ˆä¸Šä¸­ä¸‹ï¼‰ï¼Œä¾‹å¦‚2,4,4,4,8,8,8,8,12,12,12,12,16,12,12,12,12,8,8,8,8,4,4,4,2", value="")
                        block_alphas = gr.Textbox(lines=1, label="çº¿æ€§alphaåˆ†å±‚", placeholder="ç•™ç©ºåˆ™ä¸å¯ç”¨",\
                                      info="25å±‚ï¼ˆä¸Šä¸­ä¸‹ï¼‰ï¼Œä¾‹å¦‚2,2,2,2,4,4,4,4,6,6,6,6,8,6,6,6,6,4,4,4,4,2,2,2,2", value="")
                with gr.Row():
                        conv_block_dims = gr.Textbox(lines=1, label="å·ç§¯dimåˆ†å±‚", placeholder="ç•™ç©ºåˆ™ä¸å¯ç”¨",\
                                        info="25å±‚ï¼ˆä¸Šä¸­ä¸‹ï¼‰ï¼Œä¾‹å¦‚2,2,2,2,4,4,4,4,6,6,6,6,8,6,6,6,6,4,4,4,4,2,2,2,2", value="")
                        conv_block_alphas = gr.Textbox(lines=1, label="å·ç§¯alphaåˆ†å±‚", placeholder="ç•™ç©ºåˆ™ä¸å¯ç”¨",\
                                        info="25å±‚ï¼ˆä¸Šä¸­ä¸‹ï¼‰ï¼Œä¾‹å¦‚2,2,2,2,4,4,4,4,6,6,6,6,8,6,6,6,6,4,4,4,4,2,2,2,2", value="")


    def dict_key_list_2_list(dict_key_list):
        """ è¾“å…¥ä¸€ä¸ªå­—ç¬¦ä¸²listï¼Œå°†ä¼šä»å…¨å±€å˜é‡ä¸­æ‰¾åˆ°åŒæ ·åå­—çš„å˜é‡ï¼ˆåœ¨è¿™é‡Œä¸ºwebuiä¸­ç»„ä»¶å˜é‡ï¼‰æ¥è¿”å›parameter_listæ–¹ä¾¿å‘ä¸‰ä¸ªparameter_get()å‡½æ•°ä¼ é€’"""
        """ åŒæ—¶è¿”å›parameter_listçš„é•¿åº¦ï¼Œæ–¹ä¾¿ç¡®è®¤å„æ ‡ç­¾é¡µä¸­ç»„ä»¶æ•° """
        list = []
        for key in dict_key_list:
            try:
                list.append(globals()[key])
            except KeyError:
                print(f"Error: parameter_dict_key_listä¸­{key}ä¸å­˜åœ¨")
        list_len = len(list)
        return list, list_len

    common_parameter_dict_key_list = ["train_data_dir",
                      "reg_data_dir",
                      "prior_loss_weight",
                      "base_model_dir",
                      "base_model_name",
                      "use_vae",
                      "vae_model_dir",
                      "vae_model_name",
                      "width",
                      "height",
                      "batch_size",
                      "noise_offset",
                      "keep_tokens",
                      "min_snr_gamma",
                      "max_train_method",
                      "max_train_value",
                      "output_dir",
                      "output_name",
                      "save_model_as",
                      "save_every_n_epochs",
                      "save_n_epoch_ratio",
                      "save_last_n_epochs",
                      "save_state",
                      "use_wandb",
                      "wandb_api_key",
                      "log_tracker_name",
                      "optimizer_type",
                      "unet_lr",
                      "text_encoder_lr",
                      "lr_scheduler",
                      "lr_warmup_steps",
                      "lr_restart_cycles",
                      "train_method",
                      "network_dim",
                      "network_alpha",
                      "conv_dim",
                      "conv_alpha",
                      "unit",
                      "v2",
                      "v_parameterization",
                      "lowram",
                      "xformers",
                      "cache_latents",
                      "shuffle_caption",
                      "enable_bucket"]
    common_parameter_list, parameter_len_dict["common"] = dict_key_list_2_list(common_parameter_dict_key_list)
    sample_parameter_dict_key_list = ["sample_every_n_type",
                      "sample_every_n_type_value",
                      "sample_sampler",
                      "sample_seed",
                      "sample_width",
                      "sample_height",
                      "sample_scale",
                      "sample_steps",
                      "prompt",
                      "negative"]
    sample_parameter_list, parameter_len_dict["sample"] = dict_key_list_2_list(sample_parameter_dict_key_list)
    plus_parameter_dict_key_list = ["use_retrain",
                    "retrain_dir",
                    "min_bucket_reso",
                    "max_bucket_reso",
                    "clip_skip",
                    "max_token_length",
                    "caption_extension",
                    "seed",
                    "network_train_unet_only",
                    "network_train_text_encoder_only",
                    "up_lr_weight",
                    "mid_lr_weight",
                    "down_lr_weight",
                    "block_dims",
                    "block_alphas",
                    "conv_block_dims",
                    "conv_block_alphas"]
    plus_parameter_list, parameter_len_dict["plus"] = dict_key_list_2_list(plus_parameter_dict_key_list)

    #æ³¨æ„ï¼Œè¿™å‡ ä¸ªlistç›¸åŠ çš„é¡ºåºä¸èƒ½é”™,ä½†æ˜¯ä¸Šé¢ä¸‰ä¸ªparameter_dict_key_listå†…çš„å­—ç¬¦ä¸²å…ƒç´ é¡ºåºå¯ä»¥å˜(å»ºè®®ä¸è¦è¿™ä¹ˆåš)
    all_parameter_list = common_parameter_list + sample_parameter_list + plus_parameter_list
    all_parameter_dict_key_list = common_parameter_dict_key_list + sample_parameter_dict_key_list + plus_parameter_dict_key_list

    save_webui_config_button.click(fn=save_webui_config,
                    inputs=[save_webui_config_dir, save_webui_config_name, write_files_dir],
                    outputs=save_read_webui_config_title      
    )
    read_webui_config_get_button.click(fn=read_webui_config_get,
                      inputs=[read_webui_config_dir],
                      outputs=[read_webui_config_name]       
    )
    read_webui_config_button.click(fn=read_webui_config,
                    inputs=[read_webui_config_dir, read_webui_config_name, write_files_dir] + all_parameter_list,
                    outputs=[save_read_webui_config_title, write_files_dir] + all_parameter_list
    )
    common_parameter_get_button.click(fn=common_parameter_get,
                    inputs=common_parameter_list,
                    outputs=[common_parameter_toml,  common_parameter_title]
    )
    sample_parameter_get_button.click(fn=sample_parameter_get,
                    inputs=sample_parameter_list,
                    outputs=[sample_parameter_toml,  sample_parameter_title]
    )
    plus_parameter_get_button.click(fn=plus_parameter_get,
                    inputs=plus_parameter_list,
                    outputs=[plus_parameter_toml,  plus_parameter_title]
    )
    all_parameter_get_button.click(fn=all_parameter_get,
                    inputs=all_parameter_list,
                    outputs=[common_parameter_toml, sample_parameter_toml, plus_parameter_toml,  write_files_title]
    )
    base_model_get_button.click(fn=model_get,
                  inputs=[base_model_dir],
                  outputs=[base_model_name]
    )
    vae_model_get_button.click(fn=model_get,
                  inputs=[vae_model_dir],
                  outputs=[vae_model_name]
    )
    write_files_button.click(fn=write_files,
                inputs=[write_files_dir],
                outputs=[write_files_title]
    )


if __name__ == "__main__":
    demo.launch(share=False,inbrowser=False,inline=True,debug=False)
