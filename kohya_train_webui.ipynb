{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyP62JpBpGuo9dwi5LI/mwd8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WSH032/kohya-config-webui/blob/main/kohya_train_webui.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| ![visitors](https://visitor-badge.glitch.me/badge?page_id=wsh.kohya_train_webui) | [![GitHub Repo stars](https://img.shields.io/github/stars/WSH032/kohya-config-webui?style=social)](https://github.com/WSH032/kohya-config-webui)</a> |"
      ],
      "metadata": {
        "id": "ll6PRAEKIfjT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(ä¸€)å®Œæˆææ–™ä¸‹è½½"
      ],
      "metadata": {
        "id": "Led8SgZ0YnGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##**ï¼ˆç¡®ä¿ä½ ç”¨çš„æ˜¯GPUè¿è¡Œæ—¶ï¼‰**æŒ‚è½½è°·æ­Œç¡¬ç›˜,å…‹éš†kohyaçš„åº“\n",
        "\n",
        "#æŒ‚è½½è°·æ­Œç¡¬ç›˜\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "!echo \"googleç¡¬ç›˜æŒ‚è½½å®Œæˆ.\"\n",
        "\n",
        "!pip install gradio > /dev/null 2>&1\n",
        "#å®‰è£…aria2\n",
        "!apt -qq install liblz4-tool aria2  > /dev/null 2>&1\n",
        "#@title å…‹éš†kohyaçš„åº“ \n",
        "%cd /content\n",
        "!git clone https://github.com/kohya-ss/sd-scripts.git"
      ],
      "metadata": {
        "cellView": "form",
        "id": "sGDquRQCOMzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ####æ‹·è´ææ–™(æ”¯æŒé‡å¤è®­ç»ƒæ—¶é€‰æ‹©æ–°çš„è·¯å¾„)\n",
        "\n",
        "\n",
        "#@markdown è®­ç»ƒé›†åœ¨`/content/train/data`\n",
        "\n",
        "#@markdown æ­£åˆ™åŒ–åœ¨`/content/train/reg`\n",
        "\n",
        "#@markdown æ˜¯å¦ä½¿ç”¨è‡ªå®šä¹‰è·¯å¾„ï¼Œæ˜¯å¦æ‹·è´æ­£åˆ™åŒ–å›¾ç‰‡\n",
        "use_data_dir_self = False #@param {type:\"boolean\"}\n",
        "copy_reg = False #@param {type:\"boolean\"}\n",
        "#@markdown è‡ªå®šä¹‰è®­ç»ƒé›†è·¯å¾„ï¼Œæ­£åˆ™åŒ–é›†è·¯å¾„ï¼ˆä»…åœ¨å‹¾é€‰åæœ‰æ•ˆï¼‰**ï¼ˆä¸è¦ä½¿ç”¨å¸¦ç©ºæ ¼ã€ä¸­æ–‡çš„è·¯å¾„ï¼‰**\n",
        "train_data_dir_self = \"/content/drive/MyDrive/Lora/input/\" #@param {type:'string'}\n",
        "reg_data_dir_self = \"/content/drive/MyDrive/Lora/reg/\" #@param {type:'string'}\n",
        "\n",
        "train_data_dir = \"/content/train/data\"\n",
        "reg_data_dir = \"/content/train/reg\"\n",
        "\n",
        "if use_data_dir_self:\n",
        "  print(f\"ä½ ä½¿ç”¨çš„æ˜¯è‡ªå®šä¹‰è·¯å¾„\")\n",
        "else:\n",
        "  train_data_dir_self = \"/content/drive/MyDrive/Lora/input/\"\n",
        "  reg_data_dir_self = \"/content/drive/MyDrive/Lora/reg/\"\n",
        "  print(f\"ä½ ä½¿ç”¨çš„æ˜¯é»˜è®¤è·¯å¾„\")\n",
        "print(f\"è®­ç»ƒé›†åœ°å€ä¸º:{train_data_dir_self}\")\n",
        "\n",
        "#åˆ é™¤ä¹‹å‰çš„è®­ç»ƒææ–™\n",
        "!mkdir -p /content/lora-scripts/train/  #é˜²æ­¢é¦–æ¬¡è¿è¡ŒæŠ¥é”™\n",
        "!rm -r /content/lora-scripts/train/\n",
        "\n",
        "#ä»è°·æ­Œç¡¬ç›˜ä¸­æ‹·è´ä½ ä¹‹å‰ä¸Šä¼ çš„è®­ç»ƒææ–™\n",
        "print(\"æ‹·è´è®­ç»ƒé›†ä¸­\")\n",
        "!mkdir -p {train_data_dir}\n",
        "!cp -r {train_data_dir_self}/* {train_data_dir}\n",
        "!echo \"copyè®­ç»ƒææ–™å®Œæˆ.\"\n",
        "\n",
        "if copy_reg:\n",
        "  #æ‹·è´æ­£åˆ™åŒ–å›¾ç‰‡\n",
        "  print(f\"æ­£åˆ™åŒ–é›†åœ°å€ä¸º:{reg_data_dir_self}\")\n",
        "  print(\"æ‹·è´æ­£åˆ™åŒ–é›†ä¸­\")\n",
        "  !mkdir -p {reg_data_dir}\n",
        "  !cp -r {reg_data_dir_self}/* {reg_data_dir}\n",
        "  !echo \"copyæ­£åˆ™åŒ–å›¾ç‰‡å®Œæˆ.\"\n",
        "else:\n",
        "  print(\"ä¸æ‹·è´æ­£åˆ™åŒ–é›†\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "EzHADOPZMlN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### ä¸‹è½½æ¨¡å‹\n",
        "installModels = []\n",
        "installv2Models = []\n",
        "\n",
        "\n",
        "#@markdown **ä¸‹è½½åœ°å€åœ¨`/content/sd-models/`**\n",
        "#@markdown **å¯ä»¥åå¤ä¸‹è½½å¤šä¸ªæ¨¡å‹ï¼Œåˆ«æŠŠç£ç›˜ææ»¡å°±è¡Œ**\n",
        "\n",
        "#@markdown SD1.x model\n",
        "modelName = \"Animefull-final-pruned\"  # @param [\"\", \"Animefull-final-pruned\", \"Stable-Diffusion-v1-5\", \"Anything-v3-1\", \"AnyLoRA\", \"AnimePastelDream\", \"Chillout-mix\", \"OpenJourney-v4\"]\n",
        "#@markdown SD2.x model\n",
        "v2ModelName = \"\"  # @param [\"\", \"stable-diffusion-2-1-base\", \"stable-diffusion-2-1-768v\", \"plat-diffusion-v1-3-1\", \"replicant-v1\", \"illuminati-diffusion-v1-0\", \"illuminati-diffusion-v1-1\", \"waifu-diffusion-1-4-anime-e2\", \"waifu-diffusion-1-5-e2\", \"waifu-diffusion-1-5-e2-aesthetic\"]\n",
        "\n",
        "#@markdown **è‡ªå®šä¹‰æ¨¡å‹é“¾æ¥ä¾‹å¦‚`https://huggingface.co/a1079602570/animefull-final-pruned/resolve/main/novelailatest-pruned.ckpt`**\n",
        "\n",
        "#@markdown **æˆ–è€…è‡ªå®šä¹‰æ¨¡å‹è·¯å¾„ä¾‹å¦‚`/content/drive/MyDrive/Lora/model/your_model.ckpt`**\n",
        "\n",
        "\n",
        "\n",
        "base_model_url = \"\" #@param {type:\"string\"}\n",
        "\n",
        "base_model_self_dir = \"\" #@param {type:\"string\"}\n",
        "\n",
        "base_model_extension = \"ckpt\" #@param [\"ckpt\", \"safetensors\", \"pt\"]\n",
        "\n",
        "\n",
        "modelUrl = [\n",
        "    \"\",\n",
        "    \"https://huggingface.co/Linaqruf/personal-backup/resolve/main/models/animefull-final-pruned.ckpt\",\n",
        "    \"https://huggingface.co/cag/anything-v3-1/resolve/main/anything-v3-1.safetensors\",\n",
        "    \"https://huggingface.co/Lykon/AnyLoRA/resolve/main/AnyLoRA_noVae_fp16.safetensors\",\n",
        "    \"https://huggingface.co/Lykon/AnimePastelDream/resolve/main/AnimePastelDream_Soft_noVae_fp16.safetensors\",\n",
        "    \"https://huggingface.co/Linaqruf/stolen/resolve/main/pruned-models/chillout_mix-pruned.safetensors\",\n",
        "    \"https://huggingface.co/prompthero/openjourney-v4/resolve/main/openjourney-v4.ckpt\",\n",
        "    \"https://huggingface.co/Linaqruf/stolen/resolve/main/pruned-models/stable_diffusion_1_5-pruned.safetensors\",\n",
        "]\n",
        "modelList = [\n",
        "    \"\",\n",
        "    \"Animefull-final-pruned\",\n",
        "    \"Anything-v3-1\",\n",
        "    \"AnyLoRA\",\n",
        "    \"AnimePastelDream\",    \n",
        "    \"Chillout-mix\",\n",
        "    \"OpenJourney-v4\",\n",
        "    \"Stable-Diffusion-v1-5\",\n",
        "]\n",
        "v2ModelUrl = [\n",
        "    \"\",\n",
        "    \"https://huggingface.co/stabilityai/stable-diffusion-2-1-base/resolve/main/v2-1_512-ema-pruned.safetensors\",\n",
        "    \"https://huggingface.co/stabilityai/stable-diffusion-2-1/resolve/main/v2-1_768-ema-pruned.safetensors\",\n",
        "    \"https://huggingface.co/p1atdev/pd-archive/resolve/main/plat-v1-3-1.safetensors\",\n",
        "    \"https://huggingface.co/gsdf/Replicant-V1.0/resolve/main/Replicant-V1.0.safetensors\",\n",
        "    \"https://huggingface.co/IlluminatiAI/Illuminati_Diffusion_v1.0/resolve/main/illuminati_diffusion_v1.0.safetensors\",\n",
        "    \"https://huggingface.co/4eJIoBek/Illuminati-Diffusion-v1-1/resolve/main/illuminatiDiffusionV1_v11.safetensors\",\n",
        "    \"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/wd-1-4-anime_e2.ckpt\",\n",
        "    \"https://huggingface.co/waifu-diffusion/wd-1-5-beta2/resolve/main/checkpoints/wd-1-5-beta2-fp32.safetensors\",\n",
        "    \"https://huggingface.co/waifu-diffusion/wd-1-5-beta2/resolve/main/checkpoints/wd-1-5-beta2-aesthetic-fp32.safetensors\",\n",
        "]\n",
        "v2ModelList = [\n",
        "    \"\",\n",
        "    \"stable-diffusion-2-1-base\",\n",
        "    \"stable-diffusion-2-1-768v\",\n",
        "    \"plat-diffusion-v1-3-1\",\n",
        "    \"replicant-v1\",\n",
        "    \"illuminati-diffusion-v1-0\",\n",
        "    \"illuminati-diffusion-v1-1\",\n",
        "    \"waifu-diffusion-1-4-anime-e2\",\n",
        "    \"waifu-diffusion-1-5-e2\",\n",
        "    \"waifu-diffusion-1-5-e2-aesthetic\",\n",
        "]\n",
        "if modelName:\n",
        "    installModels.append((modelName, modelUrl[modelList.index(modelName)]))\n",
        "if v2ModelName:\n",
        "    installv2Models.append((v2ModelName, v2ModelUrl[v2ModelList.index(v2ModelName)]))\n",
        "\n",
        "\n",
        "#ä¸‹è½½è·¯å¾„\n",
        "base_model_dir = \"/content/sd-models/\"\n",
        "\n",
        "#æ£€æŸ¥è¿æ¥æ˜¯å¦å«æœ‰æ‰©å±•åä¿¡æ¯ï¼Œä¸å«æœ‰åˆ™ç”±ç”¨æˆ·æŒ‡å®š\n",
        "def check_ext(url):\n",
        "  if url.endswith(\".ckpt\"):\n",
        "    return \"ckpt\"\n",
        "  elif url.endswith(\".safetensors\"):\n",
        "    return \"safetensors\"\n",
        "  else:\n",
        "    return base_model_extension\n",
        "#ä¸‹è½½æ¨¡å‹\n",
        "def install(checkpoint_name, url):\n",
        "    ext = check_ext(url)\n",
        "    hf_token = \"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\"\n",
        "    user_header = f'\"Authorization: Bearer {hf_token}\"'\n",
        "    !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {base_model_dir} -o {checkpoint_name}.{ext} {url}\n",
        "    return f\"{checkpoint_name}.{ext}\"   #è¿”å›æ¨¡å‹åç§°\n",
        "def install_checkpoint():\n",
        "    for model in installModels:\n",
        "        return install(model[0], model[1])\n",
        "    for v2model in installv2Models:\n",
        "        return install(v2model[0], v2model[1])\n",
        "\n",
        "#å°è¯•ä¸‹è½½é¢„è®¾æ¨¡å‹\n",
        "base_model_name = install_checkpoint()\n",
        "#é¢„è®¾ä¸‹è½½æˆåŠŸï¼Œåˆ™å®Œæˆè·¯å¾„ä¿®æ”¹\n",
        "if base_model_name:\n",
        "  pretrained_model = base_model_dir + base_model_name\n",
        "#ä¸‹è½½å¤±è´¥ï¼Œbase_model_nameä¸ºnon\n",
        "else:\n",
        "  #ä¸ç•™ç©ºï¼Œåˆ™å°è¯•ç”¨è¿æ¥ä¸‹è½½\n",
        "  if base_model_url:\n",
        "    base_model_name = \"download.\" + check_ext(base_model_url)\n",
        "    pretrained_model = base_model_dir + base_model_name\n",
        "    !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -d {base_model_dir} -o {base_model_name} --allow-overwrite {base_model_url}\n",
        "  #ç•™ç©ºï¼Œå°†è€ƒè™‘ä»è‡ªå®šä¹‰è·¯å¾„ä¸­æ‹·è´\n",
        "  else:\n",
        "    if base_model_self_dir:\n",
        "      base_model_name = \"self.\" + check_ext(base_model_self_dir)\n",
        "      pretrained_model = base_model_dir + base_model_name\n",
        "      !cp {base_model_self_dir} {pretrained_model}\n",
        "    else:\n",
        "      print(\"ä½ æ ¹æœ¬æ²¡é€‰æ‹©ä»»ä½•æ¨¡å‹ï¼\")\n",
        "\n",
        "\n",
        "#è¾“å‡ºæ¨¡å‹ä¿¡æ¯\n",
        "print(f\"ä½ é€‰æ‹©çš„æ˜¯: {base_model_name} æ¨¡å‹\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "OYGUN309MuUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ##  ä¸‹è½½vaeï¼ˆå¯é€‰ï¼‰\n",
        "\n",
        "#@markdown **ä¸‹è½½åœ°å€åœ¨`/content/vae/`**\n",
        "\n",
        "#å‚¨å­˜ä¸‹è½½ä¿¡æ¯å‚æ•°\n",
        "installVae = []\n",
        "#@markdown é€‰æ‹© `none` æ„å‘³ç€ä¸ä½¿ç”¨vae\n",
        "\n",
        "#@markdown é€‰æ‹©ä¸€ä¸ªVaeä¸‹è½½å¹¶ä½¿ç”¨`\"animevae.pt\", \"kl-f8-anime.ckpt\", \"vae-ft-mse-840000-ema-pruned.ckpt\"`\n",
        "\n",
        "vaeUrl = [\n",
        "    \"\",\n",
        "    \"https://huggingface.co/Linaqruf/personal-backup/resolve/main/vae/animevae.pt\",\n",
        "    \"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime.ckpt\",\n",
        "    \"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.ckpt\",\n",
        "]\n",
        "vaeList = [\"none\", \"anime.vae.pt\", \"waifudiffusion.vae.pt\", \"stablediffusion.vae.pt\"]\n",
        "vaeName = \"none\"  # @param [\"none\", \"anime.vae.pt\", \"waifudiffusion.vae.pt\", \"stablediffusion.vae.pt\"]\n",
        "\n",
        "installVae.append((vaeName, vaeUrl[vaeList.index(vaeName)]))\n",
        "\n",
        "#å¼€å§‹ä¸‹è½½\n",
        "vae_dir = \"/content/vae/\"\n",
        "def install(vae_name, url):\n",
        "    hf_token = \"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\"\n",
        "    user_header = f'\"Authorization: Bearer {hf_token}\"'\n",
        "    !aria2c --console-log-level=error --allow-overwrite --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {vae_dir} -o \"vae.pt\" \"{url}\"\n",
        "\n",
        "def install_vae():\n",
        "    if vaeName != \"none\":\n",
        "        for vae in installVae:\n",
        "            install(vae[0], vae[1])\n",
        "    else:\n",
        "        pass\n",
        "install_vae()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "hiA3z5rPNriX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(äºŒ)è®¾ç½®å‚æ•°\n"
      ],
      "metadata": {
        "id": "mAeB_J7sYrmk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title WebUIè®¾ç½®å‚æ•°\n",
        "\n",
        "#@markdown **ä½¿ç”¨æ–¹æ³•ï¼Œè¿è¡Œä»£ç å—åï¼Œæ‰“å¼€è¾“å‡ºçš„è¿æ¥ç”¨å¦ä¸€ä¸ªç½‘é¡µæ“ä½œæ›´æ–¹ä¾¿ï¼Œé™¤äº†ä¸‹æ–¹ç»™å‡ºçš„å‚æ•°ä½ è¦æŒ‰ç€å¡«ï¼Œå…¶ä½™çš„åœ¨WebUIé‡Œè®¾ç½®å°±è¡Œ**`å°è´´å£«:ä½ æ‰“å¼€WebUIåï¼Œå°±å¯ä»¥ç›´æ¥è¿è¡Œä¸‹é¢å®‰è£…ä¾èµ–ç¯å¢ƒé‚£ä¸€æ­¥ï¼Œå®‰è£…å’Œå‚æ•°è®¾ç½®å¯ä»¥åŒæ—¶è¿›è¡Œ,WebUIä¼šä¸€ç›´åœ¨åå°`\n",
        "\n",
        "#@markdown å†™å…¥æ–‡ä»¶å¤¹ `/content/sd-scripts`\n",
        "\n",
        "#@markdown train_data_dir `/content/train/data`\n",
        "\n",
        "#@markdown reg_data_dirï¼ˆå¯é€‰ï¼‰ `/content/train/reg`\n",
        "\n",
        "#@markdown åº•æ¨¡æ–‡ä»¶å¤¹åœ°å€ `/content/sd-models`\n",
        "\n",
        "#@markdown ä½¿ç”¨vae(å¯é€‰) `/content/vae`\n",
        "\n",
        "#@markdown æ¨¡å‹ã€logæ—¥å¿—è¾“å‡ºåœ°å€ `æŒ‰è‡ªå·±æƒ³ä¿å­˜çš„åœ°æ–¹å¡«`\n",
        "\n",
        "import os\n",
        "import toml\n",
        "import warnings\n",
        "import gradio as gr\n",
        "\n",
        "common_parameter_dict_key_list=[]\n",
        "sample_parameter_dict_key_list=[]\n",
        "plus_parameter_dict_key_list=[]\n",
        "\n",
        "common_parameter_dict=({})\n",
        "sample_parameter_dict=({})\n",
        "plus_parameter_dict=({})\n",
        "\n",
        "random_symbol = '\\U0001f3b2\\ufe0f'  # ğŸ²ï¸\n",
        "reuse_symbol = '\\u267b\\ufe0f'  # â™»ï¸\n",
        "paste_symbol = '\\u2199\\ufe0f'  # â†™\n",
        "refresh_symbol = '\\U0001f504'  # ğŸ”„\n",
        "save_style_symbol = '\\U0001f4be'  # ğŸ’¾\n",
        "apply_style_symbol = '\\U0001f4cb'  # ğŸ“‹\n",
        "clear_prompt_symbol = '\\U0001f5d1\\ufe0f'  # ğŸ—‘ï¸\n",
        "extra_networks_symbol = '\\U0001F3B4'  # ğŸ´\n",
        "switch_values_symbol = '\\U000021C5' # â‡…\n",
        "folder_symbol = '\\U0001f4c2'  # ğŸ“‚\n",
        "\n",
        "parameter_len_dict={\"common\":0, \"sample\":0, \"plus\":0}\n",
        "\n",
        "def check_len_and_2dict(args, parameter_len_dict_value, parameter_dict_key_list, func_name=\"\"):\n",
        "    if len(args) != parameter_len_dict_value:\n",
        "        warnings.warn(f\"ä¼ å…¥{func_name}çš„å‚æ•°é•¿åº¦ä¸åŒ¹é…\", UserWarning)\n",
        "    if len(parameter_dict_key_list) != parameter_len_dict_value:\n",
        "        warnings.warn(f\" {func_name}å†…éƒ¨å­—å…¸èµ‹å€¼å…³é”®å­—åˆ—è¡¨çš„é•¿åº¦ä¸åŒ¹é…\", UserWarning)\n",
        "    parameter_dict = dict(zip(parameter_dict_key_list, args))\n",
        "    return parameter_dict\n",
        "\n",
        "def common_parameter_get(*args):\n",
        "    global common_parameter_dict\n",
        "    common_parameter_dict = check_len_and_2dict(args, parameter_len_dict[\"common\"], common_parameter_dict_key_list, func_name=\"common_parameter_get\")\n",
        "    common_parameter_toml = toml.dumps(common_parameter_dict)\n",
        "    common_parameter_title = \"åŸºç¡€å‚æ•°é…ç½®ç¡®è®¤\"\n",
        "    return common_parameter_toml,  common_parameter_title\n",
        "\n",
        "def sample_parameter_get(*args):\n",
        "    global sample_parameter_dict\n",
        "    sample_parameter_dict = check_len_and_2dict(args, parameter_len_dict[\"sample\"], sample_parameter_dict_key_list, func_name=\"sample_parameter_get\")\n",
        "    sample_parameter_toml = toml.dumps(sample_parameter_dict)\n",
        "    sample_parameter_title = \"é‡‡æ ·é…ç½®ç¡®è®¤\"\n",
        "    return sample_parameter_toml,  sample_parameter_title\n",
        "\n",
        "\n",
        "def plus_parameter_get(*args):\n",
        "    global plus_parameter_dict\n",
        "    plus_parameter_dict = check_len_and_2dict(args, parameter_len_dict[\"plus\"], plus_parameter_dict_key_list, func_name=\"plus_parameter_get\")\n",
        "    plus_parameter_toml = toml.dumps(plus_parameter_dict)\n",
        "    plus_parameter_title = \"è¿›é˜¶å‚æ•°é…ç½®ç¡®è®¤\"\n",
        "    return plus_parameter_toml,  plus_parameter_title\n",
        "\n",
        "\n",
        "def all_parameter_get(*args):\n",
        "    if len(args) != sum( parameter_len_dict.values() ):\n",
        "         warnings.warn(f\"ä¼ å…¥all_parameter_getçš„å‚æ•°é•¿åº¦ä¸åŒ¹é…\", UserWarning)\n",
        "    common_parameter_toml,  common_parameter_title = common_parameter_get( *args[ : parameter_len_dict[\"common\"] ] )\n",
        "    sample_parameter_toml,  sample_parameter_title = sample_parameter_get( *args[ parameter_len_dict[\"common\"] : parameter_len_dict[\"common\"] + parameter_len_dict[\"sample\"] ] )\n",
        "    plus_parameter_toml,  plus_parameter_title = plus_parameter_get( *args[ -parameter_len_dict[\"plus\"] : ] )\n",
        "    return common_parameter_toml, sample_parameter_toml, plus_parameter_toml,  \"å…¨éƒ¨å‚æ•°ç¡®è®¤\"\n",
        "\n",
        "def model_get(model_dir):\n",
        "    model_dir = model_dir if model_dir else os.getcwd()\n",
        "    files = [f for f in os.listdir(model_dir) if os.path.isfile(os.path.join(model_dir, f))]\n",
        "    if files:\n",
        "        return model_dir, gr.update( choices=files,value=files[0] )\n",
        "    else:\n",
        "        return model_dir, gr.update( choices=[],value=\"\" )\n",
        "\n",
        "def write_files(write_files_dir):\n",
        "    write_files_dir = write_files_dir if write_files_dir else os.getcwd()\n",
        "    os.makedirs(write_files_dir, exist_ok=True)\n",
        "    config_file_toml_path = os.path.join(write_files_dir, \"config_file.toml\")\n",
        "    sample_prompts_txt_path = os.path.join(write_files_dir, \"sample_prompts.txt\")\n",
        "\n",
        "    all = {**common_parameter_dict, **sample_parameter_dict, **plus_parameter_dict}\n",
        "\n",
        "    def parameter2toml():\n",
        "\n",
        "        #ç”Ÿæˆconfig_file.tomlçš„å­—å…¸\n",
        "\n",
        "        #model_argumentséƒ¨åˆ†\n",
        "        model_arguments = { key: all.get(key) for key in [\"v2\", \"v_parameterization\"] }\n",
        "        \"\"\" ç”Ÿæˆåº•æ¨¡è·¯å¾„ \"\"\"\n",
        "        base_model_path = os.path.join( all.get(\"base_model_dir\"), all.get(\"base_model_name\") )\n",
        "        model_arguments.update( {\"pretrained_model_name_or_path\": base_model_path} )\n",
        "        \"\"\" ç”Ÿæˆvaeè·¯å¾„ \"\"\"\n",
        "        if all.get(\"use_vae\"):\n",
        "            vae_model_path = os.path.join( all.get(\"vae_model_dir\"), all.get(\"vae_model_name\") )\n",
        "            model_arguments.update( {\"vae\": vae_model_path} )\n",
        "\n",
        "        #additional_network_argumentséƒ¨åˆ†\n",
        "        additional_network_arguments = { key: all.get(key) for key in [\"unet_lr\", \"text_encoder_lr\", \"network_dim\",\\\n",
        "                                            \"network_alpha\", \"network_train_unet_only\",\\\n",
        "                                            \"network_train_text_encoder_only\"] }\n",
        "        \"\"\" ç”Ÿæˆå¦‚network_module = \"locon.locon_kohya\" \"\"\"\n",
        "        #[\"LoRA-LierLa\", \"LoRA-C3Lier\", \"LoCon_Lycoris\", \"LoHa_Lycoris\", \"DyLoRa-LierLa\", \"DyLoRa-C3Lier\"]\n",
        "        #ä¸»è¦è´Ÿè´£network_moduleçš„å‚æ•°ç”Ÿæˆ\n",
        "        def network_module_param(train_method):\n",
        "            conv_dim = all.get(\"conv_dim\") if train_method != \"DyLoRa-C3Lier\" else all.get(\"network_dim\")\n",
        "            conv_alpha = all.get(\"conv_alpha\")\n",
        "            algo = \"lora\" if train_method == \"LoCon_Lycoris\" else \"loha\"\n",
        "            unit = all.get(\"unit\")\n",
        "            if train_method in [\"LoRA-LierLa\", \"LoRA-C3Lier\"]:\n",
        "                network_module = \"networks.lora\"\n",
        "                if train_method == \"LoRA-C3Lier\":\n",
        "                    network_module_args = [f\"conv_dim={conv_dim}\", f\"conv_alpha={conv_alpha}\"]\n",
        "                else:\n",
        "                    network_module_args = []\n",
        "            elif train_method in [\"LoCon_Lycoris\", \"LoHa_Lycoris\"]:\n",
        "                network_module = \"lycoris.kohya\"\n",
        "                network_module_args = [f\"conv_dim={conv_dim}\", f\"conv_alpha={conv_alpha}\", f\"algo={algo}\"]\n",
        "            elif train_method in [\"DyLoRa-LierLa\", \"DyLoRa-C3Lier\"]:\n",
        "                network_module = \"networks.dylora\"\n",
        "                if train_method == \"DyLoRa-C3Lier\":\n",
        "                    network_module_args = [f\"conv_dim={conv_dim}\", f\"conv_alpha={conv_alpha}\", f\"unit={unit}\"]\n",
        "                else:\n",
        "                    network_module_args = [f\"unit={unit}\"]\n",
        "            else: \n",
        "                warnings.warn(f\"è®­ç»ƒæ–¹æ³•å‚æ•°ç”Ÿæˆå‡ºé”™\", UserWarning)\n",
        "            return network_module, network_module_args\n",
        "        network_module, network_module_args = network_module_param( all.get(\"train_method\") )\n",
        "        #æ›´å¤šnetwork_argséƒ¨åˆ†ï¼ˆä¸»è¦ä¸ºåˆ†å±‚è®­ç»ƒï¼‰\n",
        "        network_lr_weight_args = [ f\"{name}={all.get(name)}\" for name in [\"up_lr_weight\", \"mid_lr_weight\", \"down_lr_weight\"] if all.get(name) ]\n",
        "\n",
        "        def network_block_param(train_method):\n",
        "            lst = [\"block_dims\", \"block_alphas\", \"conv_block_dims\", \"conv_block_alphas\"]\n",
        "            if train_method == \"LoRA-LierLa\":\n",
        "                return [ f\"{name}={all.get(name)}\" for name in lst[0:1] if all.get(name) ]\n",
        "            if train_method in [\"LoRA-C3Lier\", \"LoCon_Lycoris\", \"LoHa_Lycoris\"]:\n",
        "                return [ f\"{name}={all.get(name)}\" for name in lst if all.get(name) ]\n",
        "            else:\n",
        "                return []\n",
        "        network_block_args = network_block_param( all.get(\"train_method\") )\n",
        "        \n",
        "\n",
        "        network_args = []\n",
        "        network_args.extend(network_module_args)\n",
        "        network_args.extend(network_lr_weight_args)\n",
        "        network_args.extend(network_block_args)\n",
        "\n",
        "        additional_network_arguments.update( { \"network_module\":network_module } )\n",
        "        additional_network_arguments.update( {\"network_args\":network_args} )          \n",
        "\n",
        "        #optimizer_argumentséƒ¨åˆ†\n",
        "        optimizer_arguments = { key: all.get(key) for key in [\"optimizer_type\", \"lr_scheduler\", \"lr_warmup_steps\"] }\n",
        "        \"\"\"åªæœ‰ä½™å¼¦é‡å¯è°ƒåº¦å™¨æŒ‡å®šé‡å¯æ¬¡æ•°\"\"\"\n",
        "        if all.get(\"lr_scheduler\") == \"cosine_with_restarts\":\n",
        "            optimizer_arguments.update( {\"lr_restart_cycles\":all.get(\"lr_restart_cycles\")} )\n",
        "        \"\"\"å­¦ä¹ ç‡lræŒ‡å®š=unet_lr\"\"\"\n",
        "        optimizer_arguments.update( {\"learning_rate\":all.get(\"unet_lr\")} )\n",
        "            #optimizer_argsï¼ˆå¾…æ·»åŠ ï¼‰\n",
        "\n",
        "        #dataset_argumentséƒ¨åˆ†\n",
        "        dataset_arguments = {\"cache_latents\":True,\n",
        "                    \"shuffle_caption\":True,\n",
        "                    \"enable_bucket\":True\n",
        "        }\n",
        "\n",
        "        #training_argumentséƒ¨åˆ†\n",
        "        training_arguments = { key: all.get(key) for key in [\"batch_size\", \"noise_offset\", \"keep_tokens\",\\\n",
        "                                      \"min_bucket_reso\", \"max_bucket_reso\",\\\n",
        "                                      \"caption_extension\", \"max_token_length\", \"seed\",\\\n",
        "                                      \"xformers\", \"lowram\"]\n",
        "        }\n",
        "        \"\"\"min_snr_gammaå¤§äºé›¶æ‰ç”Ÿæ•ˆ\"\"\"\n",
        "        if all.get(\"min_snr_gamma\") > 0:\n",
        "            training_arguments.update( { \"min_snr_gamma\":all.get(\"min_snr_gamma\") } )\n",
        "        \"\"\" æœ€å¤§è®­ç»ƒæ—¶é—´ \"\"\"\n",
        "        training_arguments.update( { all.get(\"max_train_method\"):all.get(\"max_train_value\") } )\n",
        "        \"\"\" è®­ç»ƒåˆ†è¾¨ç‡ \"\"\"\n",
        "        training_arguments.update( { \"resolution\":f\"{all.get('width')},{all.get('height')}\" } )\n",
        "        \"\"\" å¦‚æœv2å¼€å¯ï¼Œåˆ™ä¸æŒ‡å®šclip_skip \"\"\"\n",
        "        if not all.get(\"v2\"):\n",
        "            training_arguments.update( { \"clip_skip\":all.get(\"clip_skip\") } )\n",
        "        \"\"\" é‡è®­ç»ƒæ¨¡å— \"\"\"\n",
        "        if all.get(\"use_retrain\") == \"model\":\n",
        "            training_arguments.update( { \"network_weights\":all.get(\"retrain_dir\") } )\n",
        "        elif all.get(\"use_retrain\") == \"state\":\n",
        "            training_arguments.update( { \"resume\":all.get(\"retrain_dir\") } )\n",
        "        \"\"\"  è®­ç»ƒç²¾åº¦ã€ä¿å­˜ç²¾åº¦ \"\"\"\n",
        "        training_arguments.update( { \"mixed_precision\":\"fp16\" } )\n",
        "        training_arguments.update( { \"save_precision\":\"fp16\" } )\n",
        "        \n",
        "\n",
        "\n",
        "        #sample_prompt_argumentséƒ¨åˆ†ï¼ˆé‡‡æ ·é—´éš”ï¼Œé‡‡æ ·æ–‡ä»¶åœ°å€å¾…æ·»åŠ ï¼‰\n",
        "        sample_prompt_arguments = { key: all.get(key) for key in [\"sample_sampler\"] }\n",
        "        sample_prompt_arguments.update( {all.get(\"sample_every_n_type\"):all.get(\"sample_every_n_type_value\")} )\n",
        "\n",
        "        #dreambooth_argumentséƒ¨åˆ†\n",
        "        dreambooth_arguments = { key: all.get(key) for key in [\"train_data_dir\", \"reg_data_dir\", \"prior_loss_weight\"] }\n",
        "\n",
        "        #saving_argumentséƒ¨åˆ†\n",
        "        saving_arguments = { key: all.get(key) for key in [\"output_dir\",\\\n",
        "                                      \"output_name\", \"save_every_n_epochs\", \"save_n_epoch_ratio\",\\\n",
        "                                      \"save_last_n_epochs\", \"save_state\", \"save_model_as\" ]\n",
        "        }\n",
        "        \"\"\" æŒ‡å®šlogè¾“å‡ºç›®å½•ä¸outputç›¸åŒ \"\"\"\n",
        "        saving_arguments.update( { \"logging_dir\":os.path.join( all.get(\"output_dir\"), \"logs\" ) } )\n",
        "        \"\"\" æŒ‡å®šlogå‰ç¼€å’Œè¾“å‡ºåå­—ç›¸åŒ \"\"\"\n",
        "        saving_arguments.update( { \"log_prefix\":all.get(\"output_name\") } )\n",
        "        \n",
        "\n",
        "        toml_dict = {\"model_arguments\":model_arguments,\n",
        "               \"additional_network_arguments\":additional_network_arguments,\n",
        "               \"optimizer_arguments\":optimizer_arguments,\n",
        "               \"dataset_arguments\":dataset_arguments,\n",
        "               \"training_arguments\":training_arguments,\n",
        "               \"sample_prompt_arguments\":sample_prompt_arguments,\n",
        "               \"dreambooth_arguments\":dreambooth_arguments,\n",
        "               \"saving_arguments\":saving_arguments,\n",
        "        }\n",
        "        toml_str = toml.dumps(toml_dict)\n",
        "        return toml_str\n",
        "    def sample_parameter2txt():\n",
        "        #key_list = [\"prompt\", \"negative\", \"sample_width\", \"sample_height\", \"sample_scale\", \"sample_steps\", \"sample_seed\"]\n",
        "        sample_str = f\"\"\"{all.get(\"prompt\")}  \\\n",
        "--n {all.get(\"negative\")}  \\\n",
        "--w {all.get(\"sample_width\")}  \\\n",
        "--h {all.get(\"sample_height\")}  \\\n",
        "--l {all.get(\"sample_scale\")}  \\\n",
        "--s {all.get(\"sample_steps\")}  \\\n",
        "{f\"--d {all.get('sample_seed')}\" if all.get('sample_seed') > 0 else \"\"}\"\"\"\n",
        "\n",
        "        return sample_str\n",
        "\n",
        "    def write(content, path):\n",
        "        with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(content)\n",
        "\n",
        "    write(parameter2toml(), config_file_toml_path)\n",
        "    write(sample_parameter2txt(), sample_prompts_txt_path)\n",
        "    write_files_title = f\"å†™å…¥æˆåŠŸ,è¾“å‡ºæ–‡ä»¶åœ¨{write_files_dir}ï¼šconfig_file.tomlå’Œsample_prompts.txt\"\n",
        "    return write_files_title\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    with gr.Row():\n",
        "        write_files_button = gr.Button(\"ç”Ÿæˆtomlå‚æ•°ä¸é‡‡æ ·é…ç½®æ–‡ä»¶\")\n",
        "        all_parameter_get_button = gr.Button(\"å…¨éƒ¨å‚æ•°ç¡®è®¤\")\n",
        "        write_files_dir = gr.Textbox(lines=1, label=\"å†™å…¥æ–‡ä»¶å¤¹\", placeholder=\"æ–‡ä»¶å¤¹è·¯å¾„,ä¸å¡«å°±é»˜è®¤ä¸ºå½“å‰æ–‡ä»¶å¤¹\", value=\"\")\n",
        "    write_files_title = gr.Markdown(\"ç”Ÿæˆé€‚ç”¨äºkohya/train_network.pyçš„é…ç½®æ–‡ä»¶\")\n",
        "    with gr.Tabs():\n",
        "        with gr.TabItem(\"åŸºç¡€å‚æ•°\"):\n",
        "            common_parameter_get_button = gr.Button(\"ç¡®å®š\")\n",
        "            common_parameter_title = gr.Markdown(\"\")\n",
        "            with gr.Accordion(\"å½“å‰åŸºç¡€å‚æ•°é…ç½®\", open=False):\n",
        "                common_parameter_toml = gr.Textbox(label=\"tomlå½¢å¼\", placeholder=\"åŸºç¡€å‚æ•°\", value=\"\")\n",
        "            with gr.Row():\n",
        "                train_data_dir = gr.Textbox(lines=1, label=\"train_data_dir\", placeholder=\"è®­ç»ƒé›†è·¯å¾„\")\n",
        "            with gr.Accordion(\"ä½¿ç”¨æ­£åˆ™åŒ–(å¯é€‰)\", open=False):\n",
        "                with gr.Row():\n",
        "                    reg_data_dir = gr.Textbox(lines=1, label=\"reg_data_dir\", placeholder=\"æ­£åˆ™åŒ–é›†è·¯å¾„ï¼ˆå¡«å…¥æ„å‘³ç€å¯ç”¨æ­£åˆ™åŒ–ï¼‰\")\n",
        "                    prior_loss_weight = gr.Slider(0, 1, step=0.01, value=0.3, label=\"æ­£åˆ™åŒ–æƒé‡\")\n",
        "            with gr.Row():\n",
        "                base_model_dir = gr.Textbox(label=\"åº•æ¨¡æ–‡ä»¶å¤¹åœ°å€\", placeholder=\"æ–‡ä»¶å¤¹è·¯å¾„,ä¸å¡«å°±é»˜è®¤ä¸ºå½“å‰æ–‡ä»¶å¤¹\")\n",
        "                base_model_get_button = gr.Button(reuse_symbol)\n",
        "                base_model_name = gr.Dropdown(choices=[],label=\"åº•æ¨¡\",value=\"\")\n",
        "            with gr.Accordion(\"ä½¿ç”¨vae(å¯é€‰)\", open=False):\n",
        "                with gr.Row():\n",
        "                    vae_model_dir = gr.Textbox(label=\"vaeæ–‡ä»¶å¤¹åœ°å€\", placeholder=\"æ–‡ä»¶å¤¹è·¯å¾„,ä¸å¡«å°±é»˜è®¤ä¸ºå½“å‰æ–‡ä»¶å¤¹\")\n",
        "                    vae_model_get_button = gr.Button(reuse_symbol)\n",
        "                    vae_model_name = gr.Dropdown(choices=[],label=\"vae\",value=\"\")\n",
        "                    use_vae = gr.Checkbox(label=\"æ˜¯å¦ä½¿ç”¨vae\",value=False)\n",
        "            with gr.Row():\n",
        "                width = gr.Slider(64, 1920, step=64, value=512, label=\"è®­ç»ƒåˆ†è¾¨ç‡ï¼ˆå®½ï¼‰width\")\n",
        "                height = gr.Slider(64, 1920, step=64, value=512, label=\"è®­ç»ƒåˆ†è¾¨ç‡ï¼ˆé«˜ï¼‰height\")\n",
        "                batch_size = gr.Slider(1, 24, step=1, value=1, label=\"batchå¤§å°\")\n",
        "            with gr.Row():\n",
        "                noise_offset = gr.Slider(0, 1, step=0.01, value=0.05, label=\"noise_offset\")\n",
        "                keep_tokens = gr.Slider(0, 225, step=1, value=0, label=\"keep_tokens\")\n",
        "                min_snr_gamma = gr.Slider(0, 100, step=0.1, value=5, label=\"min_snr_gamma`è®¾ç½®ä¸º0åˆ™ä¸ç”Ÿæ•ˆ`\")\n",
        "            \"\"\"\n",
        "            with gr.Row():\n",
        "                gr.Markdown(\"repeat * å›¾ç‰‡æ•° = æ¯ä¸ªepochçš„stepsæ•°\")\n",
        "            \"\"\"\n",
        "            with gr.Row():\n",
        "                max_train_method = gr.Dropdown([\"max_train_epochs\",\"max_train_steps\"], label=\"ä»¥epochsæˆ–stepsæ¥æŒ‡å®šæœ€å¤§è®­ç»ƒæ—¶é—´\", value=\"max_train_epochs\")\n",
        "                max_train_value = gr.Number(label=\"æœ€å¤§è®­ç»ƒepochs\\stepsæ•°\", value=10, precision=0)\n",
        "            with gr.Accordion(\"è¾“å‡ºè®¾ç½®\", open=True):\n",
        "                with gr.Row():\n",
        "                    output_dir = gr.Textbox( label=\"æ¨¡å‹ã€logæ—¥å¿—è¾“å‡ºåœ°å€ï¼ˆè‡ªè¡Œä¿®æ”¹ï¼‰\", placeholder=\"æ–‡ä»¶å¤¹è·¯å¾„\",value=os.path.join(os.getcwd(),\"output\") )\n",
        "                    output_name = gr.Textbox(label=\"è¾“å‡ºæ¨¡å‹åç§°ï¼ˆè‡ªè¡Œä¿®æ”¹ï¼‰\", placeholder=\"åç§°\",value=\"output_name\")\n",
        "                    save_model_as = gr.Dropdown([\"safetensors\",\"ckpt\",\"pt\"], label=\"ä¿å­˜æ¨¡å‹æ ¼å¼\", value=\"safetensors\")\n",
        "                with gr.Row():\n",
        "                    save_every_n_epochs = gr.Slider(1, 499, step=1, value=1, label=\"æ¯nä¸ªepochä¿å­˜ä¸€æ¬¡\")\n",
        "                    save_n_epoch_ratio = gr.Slider(1, 499, step=1, value=0, label=\"ç­‰é—´éš”ä¿å­˜nä¸ª(å¦‚ä¸æŒ‡å®šä¸º0ï¼Œå°†ä¼šè¦†ç›–æ¯nä¸ªepochä¿å­˜ä¸€æ¬¡)\")\n",
        "                    save_last_n_epochs = gr.Slider(1, 499, step=1, value=499, label=\"æœ€å¤šä¿å­˜nä¸ªï¼ˆåé¢çš„å‡ºæ¥å°±ä¼šæŠŠå‰é¢åˆ äº†,ä¼˜å…ˆçº§æœ€é«˜ï¼‰\")\n",
        "                    save_state = gr.Checkbox(label=\"ä¿å­˜å­¦ä¹ çŠ¶æ€\",value=False)\n",
        "            with gr.Row():\n",
        "                optimizer_type = gr.Dropdown([\"AdamW8bit\", \"Lion\", \"DAdaptation\", \"AdamW\", \"SGDNesterov\", \"SGDNesterov8bit\", \"AdaFactor\"],\\\n",
        "                                label=\"optimizer_typeä¼˜åŒ–å™¨ç±»å‹\", value=\"AdamW8bit\")\n",
        "                unet_lr = gr.Number(label=\"unetå­¦ä¹ ç‡\", value=1e-4)\n",
        "                text_encoder_lr = gr.Number(label=\"text_encoderå­¦ä¹ ç‡\", value=1e-5)\n",
        "            with gr.Row():\n",
        "                lr_scheduler = gr.Dropdown([\"cosine_with_restarts\",\"cosine\",\"polynomial\",\"linear\",\"constant_with_warmup\",\"constant\"],\\\n",
        "                               label=\"lr_schedulerå­¦ä¹ ç‡è°ƒåº¦å™¨\", value=\"cosine_with_restarts\")\n",
        "                lr_warmup_steps = gr.Number(label=\"å‡æ¸©æ­¥æ•°\", value=0, precision=0)\n",
        "                lr_restart_cycles = gr.Number(label=\"é€€ç«é‡å¯æ¬¡æ•°\", value=1, precision=0)\n",
        "            with gr.Row():\n",
        "                train_method = gr.Dropdown([\"LoRA-LierLa\", \"LoRA-C3Lier\",\\\n",
        "                                \"LoCon_Lycoris\",\"LoHa_Lycoris\",\\\n",
        "                                \"DyLoRa-LierLa\", \"DyLoRa-C3Lier\"],\\\n",
        "                                label=\"train_methodè®­ç»ƒæ–¹æ³•\", value=\"LoRA-LierLa\")\n",
        "                network_dim = gr.Number(label=\"çº¿æ€§dim\", value=32, precision=0)\n",
        "                network_alpha = gr.Number(label=\"çº¿æ€§alphaï¼ˆå¯ä»¥ä¸ºå°æ•°ï¼‰\", value=16)\n",
        "            with gr.Accordion(\"é¢å¤–ç½‘ç»œå‚æ•°(LoRA-C3Lierã€LoConã€LoHaã€DyLoRa-C3Lieréƒ½å±äºå·ç§¯,unitä¸ºä¸¤ä¸ªDyLoRaä¸“ç”¨)\", open=True):\n",
        "                with gr.Row():\n",
        "                    with gr.Column():\n",
        "                        conv_dim = gr.Number(label=\"å·ç§¯dim\", info=\"ä½¿ç”¨DyLoRa-C3Lieræ—¶ä¼šè¢«è®¾ç½®ä¸ºç­‰äºåŸºç¡€dim\", value=8, precision=0)\n",
        "                    with gr.Column():\n",
        "                        conv_alpha = gr.Number(label=\"å·ç§¯alpha\", info=\"å¯ä»¥ä¸ºå°æ•°\", value=1)\n",
        "                    with gr.Column():\n",
        "                        unit = gr.Number(label=\"åˆ†å‰²å•ä½unit(æ•´æ•°)\", info=\"ä½¿ç”¨DyLoRaæ—¶ï¼Œè¯·è®©dimä¸ºunitçš„å€æ•°\", value=1, precision=0)\n",
        "            with gr.Row():          \n",
        "                v2 = gr.Checkbox(label=\"v2\")\n",
        "                v_parameterization = gr.Checkbox(label=\"v_parameterization\")\n",
        "                lowram = gr.Checkbox(label=\"lowram\")\n",
        "                xformers = gr.Checkbox(label=\"xformers\",value=True)\n",
        "        with gr.TabItem(\"é‡‡æ ·å‚æ•°\"):\n",
        "            sample_parameter_get_button = gr.Button(\"ç¡®å®š\")\n",
        "            sample_parameter_title = gr.Markdown(\"\")\n",
        "            with gr.Accordion(\"å½“å‰é‡‡æ ·é…ç½®\", open=False):\n",
        "                sample_parameter_toml = gr.Textbox(label=\"tomlå½¢å¼\", placeholder=\"é‡‡æ ·é…ç½®\", value=\"\")\n",
        "            with gr.Row():\n",
        "                #enable_sample = gr.Checkbox(label=\"æ˜¯å¦å¯ç”¨é‡‡æ ·åŠŸèƒ½\")\n",
        "                sample_every_n_type = gr.Dropdown([\"sample_every_n_epochs\", \"sample_every_n_steps\"], label=\"sample_every_n_type\", value=\"sample_every_n_epochs\")\n",
        "                sample_every_n_type_value = gr.Number(label=\"sample_every_n_type_value\", value=1, precision=0)\n",
        "            with gr.Row():\n",
        "                sample_sampler = gr.Dropdown([\"ddim\", \"pndm\", \"lms\", \"euler\", \"euler_a\", \"heun\",\\\n",
        "                            \"dpm_2\", \"dpm_2_a\", \"dpmsolver\",\"dpmsolver++\", \"dpmsingle\",\\\n",
        "                            \"k_lms\", \"k_euler\", \"k_euler_a\", \"k_dpm_2\", \"k_dpm_2_a\"],\\\n",
        "                            label=\"é‡‡æ ·å™¨\", value=\"euler_a\")\n",
        "                sample_width = gr.Slider(64, 1920, step=64, value=512, label=\"é‡‡æ ·å›¾ç‰‡å®½\")\n",
        "                sample_height = gr.Slider(64, 1920, step=64, value=768, label=\"é‡‡æ ·å›¾ç‰‡é«˜\")\n",
        "                sample_scale = gr.Slider(1, 30, step=0.5, value=7, label=\"æç¤ºè¯ç›¸å…³æ€§\")\n",
        "                sample_seed = gr.Number(label=\"é‡‡æ ·ç§å­(-1ä¸æ˜¯éšæœºï¼Œå¤§äº0æ‰ç”Ÿæ•ˆ)\", value=-1, precision=0)\n",
        "                sample_steps = gr.Slider(1, 150, step=1, value=24, label=\"é‡‡æ ·è¿­ä»£æ­¥æ•°\")\n",
        "            with gr.Row():\n",
        "                prompt = gr.Textbox(lines=10, label=\"prompt\", placeholder=\"æ­£é¢æç¤ºè¯\", value=\"(masterpiece, best quality, hires:1.2), 1girl, solo,\")\n",
        "                default_negative = (\"(worst quality, bad quality:1.4), \"\n",
        "                          \"lowres, bad anatomy, bad hands, text, error, \"\n",
        "                          \"missing fingers, extra digit, fewer digits, \"\n",
        "                          \"cropped, worst quality, low quality, normal quality, \"\n",
        "                          \"jpeg artifacts,signature, watermark, username, blurry,\")\n",
        "                negative = gr.Textbox(lines=10, label=\"negative\", placeholder=\"è´Ÿé¢æç¤ºè¯\", value=default_negative)\n",
        "        with gr.TabItem(\"è¿›é˜¶å‚æ•°\"):\n",
        "            plus_parameter_get_button = gr.Button(\"ç¡®å®š\")\n",
        "            plus_parameter_title = gr.Markdown(\"\")\n",
        "            with gr.Accordion(\"å½“å‰è¿›é˜¶å‚æ•°é…ç½®\", open=False):\n",
        "                plus_parameter_toml = gr.Textbox(label=\"tomlå½¢å¼\", placeholder=\"è¿›é˜¶å‚æ•°\", value=\"\")\n",
        "            with gr.Row():\n",
        "                use_retrain = gr.Dropdown([\"no\",\"model\",\"state\"], label=\"æ˜¯å¦ä½¿ç”¨é‡è®­ç»ƒ\", value=\"no\")\n",
        "                retrain_dir = gr.Textbox(lines=1, label=\"é‡è®­ç»ƒè·¯å¾„\", placeholder=\"æ¨¡å‹æˆ–è€…çŠ¶æ€è·¯å¾„\", value=\"\")\n",
        "            with gr.Row():\n",
        "                min_bucket_reso = gr.Slider(64, 1920, step=64, value=256, label=\"æœ€ä½æ¡¶åˆ†è¾¨ç‡\")\n",
        "                max_bucket_reso = gr.Slider(64, 1920, step=64, value=1024, label=\"æœ€é«˜æ¡¶åˆ†è¾¨ç‡\")\n",
        "                clip_skip = gr.Slider(0, 25, step=1, value=2, label=\"è·³è¿‡å±‚æ•°\")\n",
        "                caption_extension = gr.Textbox(lines=1, label=\"æ ‡ç­¾æ–‡ä»¶æ‰©å±•å\", placeholder=\"ä¸€èˆ¬å¡«.txtæˆ–.cap\", value=\".txt\")\n",
        "                max_token_length = gr.Slider(75, 225, step=75, value=225, label=\"è®­ç»ƒæœ€å¤§tokenæ•°\")\n",
        "                seed = gr.Number(label=\"ç§å­\", value=1337, precision=0)\n",
        "            with gr.Row():\n",
        "                network_train_unet_only= gr.Checkbox(label=\"ä»…è®­ç»ƒunetç½‘ç»œ\",value=False)\n",
        "                network_train_text_encoder_only = gr.Checkbox(label=\"ä»…è®­ç»ƒtext_encoderç½‘ç»œ\",value=False)\n",
        "            with gr.Accordion(\"åˆ†å±‚å­¦ä¹ æ¨¡å—\", open=True):\n",
        "                gr.Markdown(\"å­¦ä¹ ç‡åˆ†å±‚ï¼Œä¸ºä¸åŒå±‚çš„ç»“æ„æŒ‡å®šä¸åŒå­¦ä¹ ç‡å€æ•°\")\n",
        "                with gr.Row():\n",
        "                    with gr.Column(scale=15):\n",
        "                        up_lr_weight = gr.Textbox(lines=1, label=\"ä¸Šå±‚å­¦ä¹ ç‡æƒé‡\", placeholder=\"ç•™ç©ºåˆ™ä¸å¯ç”¨\",\\\n",
        "                                      info=\"15å±‚ï¼Œä¾‹å¦‚1.5,1.5,1.5,1.5,1.0,1.0,1.0,1.0,0.5,0.5,0.5,0.5\", value=\"\")\n",
        "                    with gr.Column(scale=1):\n",
        "                        mid_lr_weight = gr.Textbox(lines=1, label=\"ä¸­å±‚å­¦ä¹ ç‡æƒé‡\", placeholder=\"ç•™ç©ºåˆ™ä¸å¯ç”¨\",\\\n",
        "                                      info=\"1å±‚ï¼Œä¾‹å¦‚2.0\", value=\"\")\n",
        "                    with gr.Column(scale=15):\n",
        "                        down_lr_weight = gr.Textbox(lines=1, label=\"ä¸‹å±‚å­¦ä¹ ç‡æƒé‡\", placeholder=\"ç•™ç©ºåˆ™ä¸å¯ç”¨\",\\\n",
        "                                      info=\"15å±‚ï¼Œä¾‹å¦‚0.5,0.5,0.5,0.5,1.0,1.0,1.0,1.0,1.5,1.5,1.5,1.5\", value=\"\")\n",
        "                gr.Markdown(\"dimå’Œalphaåˆ†å±‚ï¼Œä¸ºä¸åŒå±‚çš„ç»“æ„æŒ‡å®šä¸åŒçš„dimå’Œalphaï¼ˆ`DyLoRa`æ— æ³•ä½¿ç”¨ï¼Œå·ç§¯åˆ†å±‚åªæœ‰`LoRa-C3Lierã€LoConã€LoHa`å¯ä»¥ä½¿ç”¨ï¼‰\")\n",
        "                with gr.Row():\n",
        "                        block_dims = gr.Textbox(lines=1, label=\"çº¿æ€§dimåˆ†å±‚\", placeholder=\"ç•™ç©ºåˆ™ä¸å¯ç”¨\",\\\n",
        "                                      info=\"25å±‚ï¼ˆä¸Šä¸­ä¸‹ï¼‰ï¼Œä¾‹å¦‚2,4,4,4,8,8,8,8,12,12,12,12,16,12,12,12,12,8,8,8,8,4,4,4,2\", value=\"\")\n",
        "                        block_alphas = gr.Textbox(lines=1, label=\"çº¿æ€§alphaåˆ†å±‚\", placeholder=\"ç•™ç©ºåˆ™ä¸å¯ç”¨\",\\\n",
        "                                      info=\"25å±‚ï¼ˆä¸Šä¸­ä¸‹ï¼‰ï¼Œä¾‹å¦‚2,2,2,2,4,4,4,4,6,6,6,6,8,6,6,6,6,4,4,4,4,2,2,2,2\", value=\"\")\n",
        "                with gr.Row():\n",
        "                        conv_block_dims = gr.Textbox(lines=1, label=\"å·ç§¯dimåˆ†å±‚\", placeholder=\"ç•™ç©ºåˆ™ä¸å¯ç”¨\",\\\n",
        "                                        info=\"25å±‚ï¼ˆä¸Šä¸­ä¸‹ï¼‰ï¼Œä¾‹å¦‚2,2,2,2,4,4,4,4,6,6,6,6,8,6,6,6,6,4,4,4,4,2,2,2,2\", value=\"\")\n",
        "                        conv_block_alphas = gr.Textbox(lines=1, label=\"å·ç§¯alphaåˆ†å±‚\", placeholder=\"ç•™ç©ºåˆ™ä¸å¯ç”¨\",\\\n",
        "                                        info=\"25å±‚ï¼ˆä¸Šä¸­ä¸‹ï¼‰ï¼Œä¾‹å¦‚2,2,2,2,4,4,4,4,6,6,6,6,8,6,6,6,6,4,4,4,4,2,2,2,2\", value=\"\")\n",
        "\n",
        "\n",
        "    def dict_key_list_2_list(dict_key_list):\n",
        "        list = []\n",
        "        for key in dict_key_list:\n",
        "            try:\n",
        "                list.append(globals()[key])\n",
        "            except KeyError:\n",
        "                print(f\"Error: parameter_dict_key_listä¸­{key}ä¸å­˜åœ¨\")\n",
        "        list_len = len(list)\n",
        "        return list, list_len\n",
        "\n",
        "    common_parameter_dict_key_list = [\"train_data_dir\",\n",
        "                      \"reg_data_dir\",\n",
        "                      \"prior_loss_weight\",\n",
        "                      \"base_model_dir\",\n",
        "                      \"base_model_name\",\n",
        "                      \"vae_model_dir\",\n",
        "                      \"vae_model_name\",\n",
        "                      \"use_vae\",\n",
        "                      \"width\",\n",
        "                      \"height\",\n",
        "                      \"batch_size\",\n",
        "                      \"noise_offset\",\n",
        "                      \"keep_tokens\",\n",
        "                      \"min_snr_gamma\",\n",
        "                      \"max_train_method\",\n",
        "                      \"max_train_value\",\n",
        "                      \"output_dir\",\n",
        "                      \"output_name\",\n",
        "                      \"save_model_as\",\n",
        "                      \"save_every_n_epochs\",\n",
        "                      \"save_n_epoch_ratio\",\n",
        "                      \"save_last_n_epochs\",\n",
        "                      \"save_state\",\n",
        "                      \"optimizer_type\",\n",
        "                      \"unet_lr\",\n",
        "                      \"text_encoder_lr\",\n",
        "                      \"lr_scheduler\",\n",
        "                      \"lr_warmup_steps\",\n",
        "                      \"lr_restart_cycles\",\n",
        "                      \"train_method\",\n",
        "                      \"network_dim\",\n",
        "                      \"network_alpha\",\n",
        "                      \"conv_dim\",\n",
        "                      \"conv_alpha\",\n",
        "                      \"unit\",\n",
        "                      \"v2\",\n",
        "                      \"v_parameterization\",\n",
        "                      \"lowram\",\n",
        "                      \"xformers\"]\n",
        "    common_parameter_list, parameter_len_dict[\"common\"] = dict_key_list_2_list(common_parameter_dict_key_list)\n",
        "    sample_parameter_dict_key_list = [\"sample_every_n_type\",\n",
        "                      \"sample_every_n_type_value\",\n",
        "                      \"sample_sampler\",\n",
        "                      \"sample_width\",\n",
        "                      \"sample_height\",\n",
        "                      \"sample_scale\",\n",
        "                      \"sample_seed\",\n",
        "                      \"sample_steps\",\n",
        "                      \"prompt\",\n",
        "                      \"negative\"]\n",
        "    sample_parameter_list, parameter_len_dict[\"sample\"] = dict_key_list_2_list(sample_parameter_dict_key_list)\n",
        "    plus_parameter_dict_key_list = [\"use_retrain\",\n",
        "                    \"retrain_dir\",\n",
        "                    \"min_bucket_reso\",\n",
        "                    \"max_bucket_reso\",\n",
        "                    \"clip_skip\",\n",
        "                    \"caption_extension\",\n",
        "                    \"max_token_length\",\n",
        "                    \"seed\",\n",
        "                    \"network_train_unet_only\",\n",
        "                    \"network_train_text_encoder_only\",\n",
        "                    \"up_lr_weight\",\n",
        "                    \"mid_lr_weight\",\n",
        "                    \"down_lr_weight\",\n",
        "                    \"block_dims\",\n",
        "                    \"block_alphas\",\n",
        "                    \"conv_block_dims\",\n",
        "                    \"conv_block_alphas\"]\n",
        "    plus_parameter_list, parameter_len_dict[\"plus\"] = dict_key_list_2_list(plus_parameter_dict_key_list)\n",
        "    all_parameter_list = common_parameter_list + sample_parameter_list + plus_parameter_list\n",
        "\n",
        "    common_parameter_get_button.click(fn=common_parameter_get,\n",
        "                    inputs=common_parameter_list,\n",
        "                    outputs=[common_parameter_toml,  common_parameter_title]\n",
        "                    )\n",
        "    sample_parameter_get_button.click(fn=sample_parameter_get,\n",
        "                    inputs=sample_parameter_list,\n",
        "                    outputs=[sample_parameter_toml,  sample_parameter_title]\n",
        "                    )\n",
        "    plus_parameter_get_button.click(fn=plus_parameter_get,\n",
        "                    inputs=plus_parameter_list,\n",
        "                    outputs=[plus_parameter_toml,  plus_parameter_title]\n",
        "                    )\n",
        "    all_parameter_get_button.click(fn=all_parameter_get,\n",
        "                    inputs=all_parameter_list,\n",
        "                    outputs=[common_parameter_toml, sample_parameter_toml, plus_parameter_toml,  write_files_title]\n",
        "                    )\n",
        "    base_model_get_button.click(fn=model_get,inputs=base_model_dir,outputs=[base_model_dir, base_model_name])\n",
        "    vae_model_get_button.click(fn=model_get,inputs=vae_model_dir,outputs=[vae_model_dir, vae_model_name])\n",
        "    write_files_button.click(fn=write_files, inputs=[write_files_dir], outputs=[write_files_title])\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(share=False,inbrowser=False,inline=True,debug=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "6ikbBvFSRQ7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title å®‰è£…ä¾èµ–ç¯å¢ƒ\n",
        "\n",
        "\n",
        "\n",
        "#install python 3.10 å®‰è£…py3.10\n",
        "!sudo apt-get update -y > /dev/null 2>&1\n",
        "!sudo apt-get install python3.10 > /dev/null 2>&1\n",
        "#change alternatives é¦–é€‰py3.9\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.9 1  > /dev/null 2>&1\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 2  > /dev/null 2>&1\n",
        "#check python version æŸ¥çœ‹ç‰ˆæœ¬ #3.10\n",
        "!python --version\n",
        "print(\"pythonå‡çº§ä¸­\")\n",
        "# install pip for new python ä¸ºpy3.10å®‰è£…pip\n",
        "!sudo apt-get install python3.10-distutils  > /dev/null 2>&1\n",
        "!wget https://bootstrap.pypa.io/get-pip.py  > /dev/null 2>&1\n",
        "!python get-pip.py  > /dev/null 2>&1\n",
        "#install colab's dependencies å®‰è£…colabä¾èµ–\n",
        "!python -m pip install ipython ipython_genutils ipykernel jupyter_console prompt_toolkit httplib2 astor  > /dev/null 2>&1\n",
        "# link to the old google package å°†py3.9çš„è°·æ­Œä¾èµ–è¿æ¥è‡³3.10\n",
        "!ln -s /usr/local/lib/python3.9/dist-packages/google \\\n",
        "/usr/local/lib/python3.10/dist-packages/google  > /dev/null 2>&1\n",
        "print(\"pythonå‡çº§å®Œæˆ\")\n",
        "\n",
        "###################################################################################\n",
        "#å®‰è£…ç›¸å…³ç¯å¢ƒ\n",
        "\n",
        "\n",
        "\n",
        "#å®‰è£…å…¶ä»–ä¾èµ–\n",
        "print(f\"å…¶ä»–ä¾èµ–å®‰è£…ä¸­ï¼Œæ­¤æ­¥è€—æ—¶è¾ƒé•¿ï¼Œè¯·è€å¿ƒç­‰å¾…\")\n",
        "%cd sd-scripts\n",
        "!pip -q install --upgrade -r requirements.txt\n",
        "print(f\"å…¶ä»–ä¾èµ–å®‰è£…å®Œæˆ\")\n",
        "\n",
        "#å®‰è£…xformers 0.0.16ç‰ˆæœ¬\n",
        "print(f\"xformerså®‰è£…ä¸­\")\n",
        "!pip -q install xformers==0.0.17\n",
        "print(f\"xformers-0.0.17å®‰è£…å®Œæˆ\")\n",
        "\n",
        "#å®‰è£…Triton\n",
        "print(f\"tritonå®‰è£…ä¸­\")\n",
        "!pip -q install triton==2.0.0\n",
        "print(f\"Tritonå®‰è£…å®Œæˆ\")\n",
        "\n",
        "#å®‰è£…lionä¼˜åŒ–å™¨ã€lycoris\n",
        "print(f\"lionä¼˜åŒ–å™¨ã€lycoriså®‰è£…ä¸­\")\n",
        "!pip -q install --upgrade lion-pytorch lycoris-lora\n",
        "print(f\"lionä¼˜åŒ–å™¨ã€lycoriså®‰è£…å®Œæˆ\")\n",
        "\n",
        "#å®‰è£…Dadaptionä¼˜åŒ–å™¨\n",
        "print(f\"Dadaptionä¼˜åŒ–å™¨å®‰è£…ä¸­\")\n",
        "!pip -q install dadaptation\n",
        "print(f\"Dadaptionä¼˜åŒ–å™¨å®‰è£…å®Œæˆ\")\n",
        "\n",
        "\n",
        "#############################\n",
        "#å¼€å¯tensorboard\n",
        "%load_ext tensorboard"
      ],
      "metadata": {
        "cellView": "form",
        "id": "mxO7gAHILhZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ï¼ˆä¸‰ï¼‰å¼€å§‹è®­ç»ƒ"
      ],
      "metadata": {
        "id": "pYZtXvtmes2I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  ### å¼€å§‹è®­ç»ƒ\n",
        "\n",
        "#@markdown è‹¥æ­£ç¡®è¿è¡Œï¼Œè®­ç»ƒå®Œæˆåï¼Œæ¨¡å‹ä¼šè‡ªåŠ¨ä¿å­˜è‡³ä½ åœ¨WebUIé‡Œè®¾ç½®çš„åœ°å€\n",
        "\n",
        "#å¼€å§‹è®­ç»ƒï¼\n",
        "%cd /content/sd-scripts\n",
        "!export TF_CPP_MIN_LOG_LEVEL=3\n",
        "!accelerate launch --num_cpu_threads_per_process 8 train_network.py --config_file=\"config_file.toml\" --sample_prompts=\"sample_prompts.txt\" \n",
        "\n",
        "\n",
        "!echo \"å®Œæˆäº† XXXD.\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "NTRgMI7jR3DY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}