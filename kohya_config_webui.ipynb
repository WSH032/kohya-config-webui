{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WSH032/kohya-config-webui/blob/main/kohya_config_webui.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| ![visitors](https://visitor-badge.glitch.me/badge?page_id=wsh.kohya_config_webui) | [![GitHub Repo stars](https://img.shields.io/github/stars/WSH032/kohya-config-webui?style=social)](https://github.com/WSH032/kohya-config-webui)</a> |\n",
        "\n",
        "#A WebUI for making config files used by kohya_sd_script\n",
        "\n",
        "Created by [WSH](https://space.bilibili.com/8417436)"
      ],
      "metadata": {
        "id": "7aje0w7w2qsc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "ec1xuZuQmvTg"
      },
      "outputs": [],
      "source": [
        "#@title å®‰è£…ä¾èµ–\n",
        "!pip install gradio   > /dev/null 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "oa6oEre6KC_B",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title å‡½æ•°éƒ¨åˆ†\n",
        "\n",
        "#A WebUI for making config files used by kohya_sd_script\n",
        "\n",
        "#Created by [WSH](https://space.bilibili.com/8417436)\n",
        "#[![GitHub Repo stars](https://img.shields.io/github/stars/WSH032/kohya-config-webui?style=social)](https://github.com/WSH032/kohya-config-webui)\n",
        "\n",
        "import os\n",
        "import toml\n",
        "import warnings\n",
        "import gradio as gr\n",
        "\n",
        "common_parameter_dict_key_list=[]\n",
        "sample_parameter_dict_key_list=[]\n",
        "plus_parameter_dict_key_list=[]\n",
        "all_parameter_dict_key_list=[]  #åé¢ä¼šæœ‰ä¸€æ¬¡all_parameter_dict_key_list = common_parameter_dict_key_list + sample_parameter_dict_key_list + plus_parameter_dict_key_list\n",
        "    \n",
        "\n",
        "common_parameter_dict=({})\n",
        "sample_parameter_dict=({})\n",
        "plus_parameter_dict=({})\n",
        "\n",
        "common_confirm_flag = False   #å¿…é¡»è¦ç¡®è®¤å¸¸è§„å‚æ•°ä¸€æ¬¡æ‰å…è®¸å†™å…¥toml\n",
        "\n",
        "parameter_len_dict={\"common\":0, \"sample\":0, \"plus\":0}\n",
        "\n",
        "random_symbol = '\\U0001f3b2\\ufe0f'  # ğŸ²ï¸\n",
        "reuse_symbol = '\\u267b\\ufe0f'  # â™»ï¸\n",
        "paste_symbol = '\\u2199\\ufe0f'  # â†™\n",
        "refresh_symbol = '\\U0001f504'  # ğŸ”„\n",
        "save_style_symbol = '\\U0001f4be'  # ğŸ’¾\n",
        "apply_style_symbol = '\\U0001f4cb'  # ğŸ“‹\n",
        "clear_prompt_symbol = '\\U0001f5d1\\ufe0f'  # ğŸ—‘ï¸\n",
        "extra_networks_symbol = '\\U0001F3B4'  # ğŸ´\n",
        "switch_values_symbol = '\\U000021C5' # â‡…\n",
        "folder_symbol = '\\U0001f4c2'  # ğŸ“‚\n",
        "\n",
        "\n",
        "def check_len_and_2dict(args, parameter_len_dict_value, parameter_dict_key_list, func_name=\"\"):\n",
        "    if len(args) != parameter_len_dict_value:\n",
        "        warnings.warn(f\"ä¼ å…¥{func_name}çš„å‚æ•°é•¿åº¦ä¸åŒ¹é…\", UserWarning)\n",
        "    if len(parameter_dict_key_list) != parameter_len_dict_value:\n",
        "        warnings.warn(f\" {func_name}å†…éƒ¨å­—å…¸èµ‹å€¼å…³é”®å­—åˆ—è¡¨çš„é•¿åº¦ä¸åŒ¹é…\", UserWarning)\n",
        "    parameter_dict = dict(zip(parameter_dict_key_list, args))\n",
        "    return parameter_dict\n",
        "\n",
        "def common_parameter_get(*args):\n",
        "    global common_parameter_dict, common_confirm_flag\n",
        "    common_confirm_flag = True    #å¿…é¡»è¦ç¡®è®¤å¸¸è§„å‚æ•°ä¸€æ¬¡æ‰å…è®¸å†™å…¥toml\n",
        "    common_parameter_dict = check_len_and_2dict(args, parameter_len_dict[\"common\"], common_parameter_dict_key_list, func_name=\"common_parameter_get\")\n",
        "    common_parameter_toml = toml.dumps(common_parameter_dict)\n",
        "    common_parameter_title = \"åŸºç¡€å‚æ•°é…ç½®ç¡®è®¤\"\n",
        "    return common_parameter_toml,  common_parameter_title\n",
        "\n",
        "def sample_parameter_get(*args):\n",
        "    global sample_parameter_dict\n",
        "    sample_parameter_dict = check_len_and_2dict(args, parameter_len_dict[\"sample\"], sample_parameter_dict_key_list, func_name=\"sample_parameter_get\")\n",
        "    sample_parameter_toml = toml.dumps(sample_parameter_dict)\n",
        "    sample_parameter_title = \"é‡‡æ ·é…ç½®ç¡®è®¤\"\n",
        "    return sample_parameter_toml,  sample_parameter_title\n",
        "\n",
        "\n",
        "def plus_parameter_get(*args):\n",
        "    global plus_parameter_dict\n",
        "    plus_parameter_dict = check_len_and_2dict(args, parameter_len_dict[\"plus\"], plus_parameter_dict_key_list, func_name=\"plus_parameter_get\")\n",
        "    plus_parameter_toml = toml.dumps(plus_parameter_dict)\n",
        "    plus_parameter_title = \"è¿›é˜¶å‚æ•°é…ç½®ç¡®è®¤\"\n",
        "    return plus_parameter_toml,  plus_parameter_title\n",
        "\n",
        "\n",
        "def all_parameter_get(*args):\n",
        "    if len(args) != sum( parameter_len_dict.values() ):\n",
        "         warnings.warn(f\"ä¼ å…¥all_parameter_getçš„å‚æ•°é•¿åº¦ä¸åŒ¹é…\", UserWarning)\n",
        "    common_parameter_toml,  common_parameter_title = common_parameter_get( *args[ : parameter_len_dict[\"common\"] ] )\n",
        "    sample_parameter_toml,  sample_parameter_title = sample_parameter_get( *args[ parameter_len_dict[\"common\"] : parameter_len_dict[\"common\"] + parameter_len_dict[\"sample\"] ] )\n",
        "    plus_parameter_toml,  plus_parameter_title = plus_parameter_get( *args[ -parameter_len_dict[\"plus\"] : ] )\n",
        "    return common_parameter_toml, sample_parameter_toml, plus_parameter_toml,  \"å…¨éƒ¨å‚æ•°ç¡®è®¤\"\n",
        "\n",
        "                      \n",
        "def save_webui_config(save_webui_config_dir, save_webui_config_name, write_files_dir):\n",
        "    os.makedirs(save_webui_config_dir, exist_ok=True)\n",
        "    \n",
        "    other = {\"write_files_dir\":write_files_dir}\n",
        "    param = {**common_parameter_dict, **sample_parameter_dict, **plus_parameter_dict}\n",
        "    dict = { \"other\":other, \"param\":param }\n",
        "\n",
        "    save_webui_config_path = os.path.join(save_webui_config_dir, save_webui_config_name)\n",
        "    with open(save_webui_config_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        webui_config_str = toml.dumps( dict )\n",
        "        f.write(webui_config_str)\n",
        "    return f\"ä¿å­˜webuié…ç½®æˆåŠŸï¼Œæ–‡ä»¶åœ¨{save_webui_config_path}\"\n",
        "\n",
        "def read_webui_config_get(read_webui_config_dir):\n",
        "    try:\n",
        "        files = [f for f in os.listdir(read_webui_config_dir) if f.endswith(\".toml\") ]\n",
        "        if files:\n",
        "            return gr.update( choices=files,value=files[0] )\n",
        "        else:\n",
        "            return gr.update( choices=[],value=\"æ²¡æœ‰æ‰¾åˆ°webuié…ç½®æ–‡ä»¶\" )\n",
        "    except Exception as e:\n",
        "        return gr.update( choices=[], value=f\"é”™è¯¯çš„æ–‡ä»¶å¤¹è·¯å¾„:{e}\" )\n",
        "\n",
        "def read_webui_config(read_webui_config_dir, read_webui_config_name, write_files_dir, *args):\n",
        "    dir_change_flag = False\n",
        "    param_len = sum( parameter_len_dict.values() )\n",
        "    if len(args) != param_len:\n",
        "        warnings.warn(f\"ä¼ å…¥read_webui_configçš„*argsé•¿åº¦ä¸åŒ¹é…\", UserWarning)\n",
        "    \n",
        "    read_webui_config_path = os.path.join(read_webui_config_dir, read_webui_config_name)\n",
        "    #èƒ½æ‰“å¼€å°±æ­£å¸¸æ“ä½œ\n",
        "    try:\n",
        "        with open(read_webui_config_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            config_dict = toml.loads( f.read() )\n",
        "        \n",
        "        #èƒ½è¯»åˆ°[\"other\"].[\"write_files_dir\"]å°±æ”¹ï¼Œè¯»ä¸åˆ°å°±ç”¨åŸå†™å…¥åœ°å€\n",
        "        try:\n",
        "            if config_dict[\"other\"][\"write_files_dir\"] != write_files_dir:\n",
        "                write_files_dir = config_dict[\"other\"][\"write_files_dir\"]\n",
        "                dir_change_flag = True\n",
        "        except KeyError:\n",
        "            pass\n",
        "        \n",
        "        param_dict_key_list = list( config_dict.get(\"param\",{}).keys() )\n",
        "        #æ‰¾å‡ºå…±æœ‰çš„keyè¿›è¡Œèµ‹å€¼ï¼Œéå…±æœ‰çš„æŠ¥é”™\n",
        "        both_key = set(all_parameter_dict_key_list) & set(param_dict_key_list)\n",
        "        parameter_unique_key = set(all_parameter_dict_key_list) - set(both_key)\n",
        "        config_unique_key = set(param_dict_key_list) - set(both_key)\n",
        "        #èµ‹å€¼\n",
        "        count = 0\n",
        "        if both_key:\n",
        "            args = list(args)\n",
        "            for key in both_key:\n",
        "                index = all_parameter_dict_key_list.index(key)\n",
        "                args[ index ] = config_dict[\"param\"][key]\n",
        "                count += 1\n",
        "            args = tuple(args)\n",
        "        read_done = f\"\\nè¯»å–å®Œæˆ,WebUIä¸­å…±æœ‰{param_len}é¡¹å‚æ•°,æ›´æ–°äº†å…¶ä¸­{count}é¡¹\\n\" + f\"å†™å…¥æ–‡ä»¶å¤¹å‘ç”Ÿæ”¹å˜:{write_files_dir}\" if dir_change_flag else \"\"\n",
        "        config_warning = f\"\\nwebui-configæ–‡ä»¶ä¸­ä»¥ä¸‹å‚æ•°å¯èƒ½å·²ç»å¤±æ•ˆæˆ–é”™è¯¯ï¼š\\n{config_unique_key}\\n\" if config_unique_key else \"\"\n",
        "        parameter_warning = f\"\\nWebUIä¸­ä»¥ä¸‹å‚æ•°åœ¨webui-configæ–‡ä»¶ä¸­æœªæ‰¾åˆ°ï¼Œä¸å‘ç”Ÿä¿®æ”¹ï¼š\\n{parameter_unique_key}\\n\" if parameter_unique_key else \"\"\n",
        "        str = read_done + config_warning + parameter_warning\n",
        "        return  str, write_files_dir, *args\n",
        "\n",
        "    #æ‰“ä¸å¼€å°±è¿”å›åŸå€¼\n",
        "    except FileNotFoundError:\n",
        "        return \"æ–‡ä»¶æˆ–ç›®å½•ä¸å­˜åœ¨\", write_files_dir, *args\n",
        "    except PermissionError:\n",
        "        return \"æ²¡æœ‰æƒé™è®¿é—®æ–‡ä»¶æˆ–ç›®å½•\", write_files_dir, *args\n",
        "    except OSError as e:\n",
        "        return f\"something wrongï¼š{e}\", write_files_dir, *args\n",
        "    \n",
        "    \n",
        "\n",
        "def model_get(model_dir):\n",
        "    try:\n",
        "        files = [f for f in os.listdir(model_dir) if os.path.isfile(os.path.join(model_dir, f))]\n",
        "        if files:\n",
        "            return gr.update( choices=files,value=files[0] )\n",
        "        else:\n",
        "            return gr.update( choices=[],value=\"æ²¡æœ‰æ‰¾åˆ°æ¨¡å‹\" )\n",
        "    except Exception as e:\n",
        "        return gr.update( choices=[], value=f\"é”™è¯¯çš„æ–‡ä»¶å¤¹è·¯å¾„:{e}\" )\n",
        "\n",
        "\n",
        "def write_files(write_files_dir):\n",
        "\n",
        "    if not common_confirm_flag:\n",
        "        return \"å¿…é¡»è¦ç¡®è®¤å¸¸è§„å‚æ•°ä¸€æ¬¡æ‰å…è®¸å†™å…¥toml\"\n",
        "\n",
        "    write_files_dir = write_files_dir if write_files_dir else os.getcwd()\n",
        "    os.makedirs(write_files_dir, exist_ok=True)\n",
        "    config_file_toml_path = os.path.join(write_files_dir, \"config_file.toml\")\n",
        "    sample_prompts_txt_path = os.path.join(write_files_dir, \"sample_prompts.txt\")\n",
        "\n",
        "    all = {**common_parameter_dict, **sample_parameter_dict, **plus_parameter_dict}\n",
        "\n",
        "    def parameter2toml():\n",
        "\n",
        "        #ç”Ÿæˆconfig_file.tomlçš„å­—å…¸\n",
        "\n",
        "        #model_argumentséƒ¨åˆ†\n",
        "        model_arguments = { key: all.get(key) for key in [\"v2\", \"v_parameterization\"] }\n",
        "        \"\"\" ç”Ÿæˆåº•æ¨¡è·¯å¾„ \"\"\"\n",
        "        base_model_path = os.path.join( all.get(\"base_model_dir\"), all.get(\"base_model_name\") )\n",
        "        model_arguments.update( {\"pretrained_model_name_or_path\": base_model_path} )\n",
        "        \"\"\" ç”Ÿæˆvaeè·¯å¾„ \"\"\"\n",
        "        if all.get(\"use_vae\"):\n",
        "            vae_model_path = os.path.join( all.get(\"vae_model_dir\"), all.get(\"vae_model_name\") )\n",
        "            model_arguments.update( {\"vae\": vae_model_path} )\n",
        "\n",
        "        #additional_network_argumentséƒ¨åˆ†\n",
        "        additional_network_arguments = { key: all.get(key) for key in [\"unet_lr\", \"text_encoder_lr\", \"network_dim\",\\\n",
        "                                            \"network_alpha\", \"network_train_unet_only\",\\\n",
        "                                            \"network_train_text_encoder_only\"] }\n",
        "        \"\"\" ç”Ÿæˆå¦‚network_module = \"locon.locon_kohya\" \"\"\"\n",
        "        #[\"LoRA-LierLa\", \"LoRA-C3Lier\", \"LoCon_Lycoris\", \"LoHa_Lycoris\", \"DyLoRa-LierLa\", \"DyLoRa-C3Lier\"]\n",
        "        #ä¸»è¦è´Ÿè´£network_moduleçš„å‚æ•°ç”Ÿæˆ\n",
        "        def network_module_param(train_method):\n",
        "            conv_dim = all.get(\"conv_dim\") if train_method != \"DyLoRa-C3Lier\" else all.get(\"network_dim\")\n",
        "            conv_alpha = all.get(\"conv_alpha\")\n",
        "            algo = \"lora\" if train_method == \"LoCon_Lycoris\" else \"loha\"\n",
        "            unit = all.get(\"unit\")\n",
        "            if train_method in [\"LoRA-LierLa\", \"LoRA-C3Lier\"]:\n",
        "                network_module = \"networks.lora\"\n",
        "                if train_method == \"LoRA-C3Lier\":\n",
        "                    network_module_args = [f\"conv_dim={conv_dim}\", f\"conv_alpha={conv_alpha}\"]\n",
        "                else:\n",
        "                    network_module_args = []\n",
        "            elif train_method in [\"LoCon_Lycoris\", \"LoHa_Lycoris\"]:\n",
        "                network_module = \"lycoris.kohya\"\n",
        "                network_module_args = [f\"conv_dim={conv_dim}\", f\"conv_alpha={conv_alpha}\", f\"algo={algo}\"]\n",
        "            elif train_method in [\"DyLoRa-LierLa\", \"DyLoRa-C3Lier\"]:\n",
        "                network_module = \"networks.dylora\"\n",
        "                if train_method == \"DyLoRa-C3Lier\":\n",
        "                    network_module_args = [f\"conv_dim={conv_dim}\", f\"conv_alpha={conv_alpha}\", f\"unit={unit}\"]\n",
        "                else:\n",
        "                    network_module_args = [f\"unit={unit}\"]\n",
        "            else: \n",
        "                warnings.warn(f\"è®­ç»ƒæ–¹æ³•å‚æ•°ç”Ÿæˆå‡ºé”™\", UserWarning)\n",
        "            return network_module, network_module_args\n",
        "        network_module, network_module_args = network_module_param( all.get(\"train_method\") )\n",
        "        #æ›´å¤šnetwork_argséƒ¨åˆ†ï¼ˆä¸»è¦ä¸ºåˆ†å±‚è®­ç»ƒï¼‰\n",
        "        network_lr_weight_args = [ f\"{name}={all.get(name)}\" for name in [\"up_lr_weight\", \"mid_lr_weight\", \"down_lr_weight\"] if all.get(name) ]\n",
        "\n",
        "        def network_block_param(train_method):\n",
        "            lst = [\"block_dims\", \"block_alphas\", \"conv_block_dims\", \"conv_block_alphas\"]\n",
        "            if train_method == \"LoRA-LierLa\":\n",
        "                return [ f\"{name}={all.get(name)}\" for name in lst[0:1] if all.get(name) ]\n",
        "            if train_method in [\"LoRA-C3Lier\", \"LoCon_Lycoris\", \"LoHa_Lycoris\"]:\n",
        "                return [ f\"{name}={all.get(name)}\" for name in lst if all.get(name) ]\n",
        "            else:\n",
        "                return []\n",
        "        network_block_args = network_block_param( all.get(\"train_method\") )\n",
        "        \n",
        "\n",
        "        network_args = []\n",
        "        network_args.extend(network_module_args)\n",
        "        network_args.extend(network_lr_weight_args)\n",
        "        network_args.extend(network_block_args)\n",
        "\n",
        "        additional_network_arguments.update( { \"network_module\":network_module } )\n",
        "        additional_network_arguments.update( {\"network_args\":network_args} )          \n",
        "\n",
        "        #optimizer_argumentséƒ¨åˆ†\n",
        "        optimizer_arguments = { key: all.get(key) for key in [\"optimizer_type\", \"lr_scheduler\", \"lr_warmup_steps\"] }\n",
        "        \"\"\"åªæœ‰ä½™å¼¦é‡å¯è°ƒåº¦å™¨æŒ‡å®šé‡å¯æ¬¡æ•°\"\"\"\n",
        "        if all.get(\"lr_scheduler\") == \"cosine_with_restarts\":\n",
        "            optimizer_arguments.update( {\"lr_restart_cycles\":all.get(\"lr_restart_cycles\")} )\n",
        "        \"\"\"å­¦ä¹ ç‡lræŒ‡å®š=unet_lr\"\"\"\n",
        "        optimizer_arguments.update( {\"learning_rate\":all.get(\"unet_lr\")} )\n",
        "            #optimizer_argsï¼ˆå¾…æ·»åŠ ï¼‰\n",
        "\n",
        "        #dataset_argumentséƒ¨åˆ†\n",
        "        dataset_arguments = { key: all.get(key) for key in [\"cache_latents\", \"shuffle_caption\", \"enable_bucket\"] }\n",
        "        \n",
        "        #training_argumentséƒ¨åˆ†\n",
        "        training_arguments = { key: all.get(key) for key in [\"batch_size\", \"noise_offset\", \"keep_tokens\",\\\n",
        "                                      \"min_bucket_reso\", \"max_bucket_reso\",\\\n",
        "                                      \"caption_extension\", \"max_token_length\", \"seed\",\\\n",
        "                                      \"xformers\", \"lowram\"]\n",
        "        }\n",
        "        \"\"\"min_snr_gammaå¤§äºé›¶æ‰ç”Ÿæ•ˆ\"\"\"\n",
        "        if all.get(\"min_snr_gamma\") > 0:\n",
        "            training_arguments.update( { \"min_snr_gamma\":all.get(\"min_snr_gamma\") } )\n",
        "        \"\"\" æœ€å¤§è®­ç»ƒæ—¶é—´ \"\"\"\n",
        "        training_arguments.update( { all.get(\"max_train_method\"):all.get(\"max_train_value\") } )\n",
        "        \"\"\" è®­ç»ƒåˆ†è¾¨ç‡ \"\"\"\n",
        "        training_arguments.update( { \"resolution\":f\"{all.get('width')},{all.get('height')}\" } )\n",
        "        \"\"\" å¦‚æœv2å¼€å¯ï¼Œåˆ™ä¸æŒ‡å®šclip_skip \"\"\"\n",
        "        if not all.get(\"v2\"):\n",
        "            training_arguments.update( { \"clip_skip\":all.get(\"clip_skip\") } )\n",
        "        \"\"\" é‡è®­ç»ƒæ¨¡å— \"\"\"\n",
        "        if all.get(\"use_retrain\") == \"model\":\n",
        "            training_arguments.update( { \"network_weights\":all.get(\"retrain_dir\") } )\n",
        "        elif all.get(\"use_retrain\") == \"state\":\n",
        "            training_arguments.update( { \"resume\":all.get(\"retrain_dir\") } )\n",
        "        \"\"\"  è®­ç»ƒç²¾åº¦ã€ä¿å­˜ç²¾åº¦ \"\"\"\n",
        "        training_arguments.update( { \"mixed_precision\":\"fp16\" } )\n",
        "        training_arguments.update( { \"save_precision\":\"fp16\" } )\n",
        "        \n",
        "\n",
        "\n",
        "        #sample_prompt_argumentséƒ¨åˆ†ï¼ˆé‡‡æ ·é—´éš”ï¼Œé‡‡æ ·æ–‡ä»¶åœ°å€å¾…æ·»åŠ ï¼‰\n",
        "        sample_prompt_arguments = { key: all.get(key) for key in [\"sample_sampler\"] }\n",
        "        if all.get(\"sample_every_n_type\"):    #å¦‚æœé‡‡æ ·éƒ¨åˆ†æ²¡ç¡®è®¤è¿‡ä¸€æ¬¡ï¼Œä¼šå‡ºç°all.get(\"sample_every_n_type\")=None:Noneçš„å­—å…¸é€ æˆæŠ¥é”™\n",
        "            sample_prompt_arguments.update( {all.get(\"sample_every_n_type\"):all.get(\"sample_every_n_type_value\")} )\n",
        "\n",
        "        #dreambooth_argumentséƒ¨åˆ†\n",
        "        dreambooth_arguments = { key: all.get(key) for key in [\"train_data_dir\", \"reg_data_dir\", \"prior_loss_weight\"] }\n",
        "\n",
        "        #saving_argumentséƒ¨åˆ†\n",
        "        saving_arguments = { key: all.get(key) for key in [\"output_dir\",\\\n",
        "                                      \"output_name\", \"save_every_n_epochs\", \"save_n_epoch_ratio\",\\\n",
        "                                      \"save_last_n_epochs\", \"save_state\", \"save_model_as\" ]\n",
        "        }\n",
        "        \"\"\" æŒ‡å®šlogè¾“å‡ºç›®å½•ä¸outputç›¸åŒ \"\"\"\n",
        "        saving_arguments.update( { \"logging_dir\":os.path.join( all.get(\"output_dir\"), \"logs\" ) } )\n",
        "        \"\"\" æŒ‡å®šlogå‰ç¼€å’Œè¾“å‡ºåå­—ç›¸åŒ \"\"\"\n",
        "        saving_arguments.update( { \"log_prefix\":all.get(\"output_name\") } )\n",
        "        \n",
        "\n",
        "        toml_dict = {\"model_arguments\":model_arguments,\n",
        "               \"additional_network_arguments\":additional_network_arguments,\n",
        "               \"optimizer_arguments\":optimizer_arguments,\n",
        "               \"dataset_arguments\":dataset_arguments,\n",
        "               \"training_arguments\":training_arguments,\n",
        "               \"sample_prompt_arguments\":sample_prompt_arguments,\n",
        "               \"dreambooth_arguments\":dreambooth_arguments,\n",
        "               \"saving_arguments\":saving_arguments,\n",
        "        }\n",
        "        toml_str = toml.dumps(toml_dict)\n",
        "        return toml_str\n",
        "    def sample_parameter2txt():\n",
        "        #key_list = [\"prompt\", \"negative\", \"sample_width\", \"sample_height\", \"sample_scale\", \"sample_steps\", \"sample_seed\"]\n",
        "\n",
        "        if not all.get('sample_seed'):    #å¦‚æœé‡‡æ ·éƒ¨åˆ†æ²¡ç¡®è®¤è¿‡ï¼Œä¼šå‡ºç°all.get('sample_seed')=None > 0é€ æˆæŠ¥é”™\n",
        "            return \"\"\n",
        "        sample_str = f\"\"\"{all.get(\"prompt\")}  \\\n",
        "--n {all.get(\"negative\")}  \\\n",
        "--w {all.get(\"sample_width\")}  \\\n",
        "--h {all.get(\"sample_height\")}  \\\n",
        "--l {all.get(\"sample_scale\")}  \\\n",
        "--s {all.get(\"sample_steps\")}  \\\n",
        "{f\"--d {all.get('sample_seed')}\" if all.get('sample_seed') > 0 else \"\"}\"\"\"\n",
        "        return sample_str\n",
        "\n",
        "    def write(content, path):\n",
        "        with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(content)\n",
        "\n",
        "    write(parameter2toml(), config_file_toml_path)\n",
        "    write(sample_parameter2txt(), sample_prompts_txt_path)\n",
        "    write_files_title = f\"å†™å…¥æˆåŠŸ, è®­ç»ƒé…ç½®æ–‡ä»¶åœ¨{config_file_toml_path}, é‡‡æ ·å‚æ•°æ–‡ä»¶åœ¨{sample_prompts_txt_path}\"\n",
        "    return write_files_title\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LT7NaOl8Jfgf",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title WebUIéƒ¨åˆ†\n",
        "\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    with gr.Accordion(\"ä¿å­˜ã€è¯»å–\\nwebuié…ç½®\", open=False):\n",
        "        save_read_webui_config_title = gr.Markdown(\"ä¿å­˜æˆ–è¯»å–\")\n",
        "        with gr.Row():\n",
        "            save_webui_config_button = gr.Button(\"ä¿å­˜\")\n",
        "        with gr.Row():\n",
        "            save_webui_config_dir = gr.Textbox(lines=1, label=\"ä¿å­˜ç›®å½•\", value=os.path.join(os.getcwd(),\"kohya_config_webui_save\") )\n",
        "            save_webui_config_name = gr.Textbox(lines=1, label=\"ä¿å­˜åå­—ï¼ˆä»¥tomlä¸ºæ‰©å±•åï¼Œå¦åˆ™ä¸ä¼šè¢«è¯»å–ï¼‰\", value=\"kohya_config_webui_save.toml\" )\n",
        "        with gr.Row():\n",
        "            read_webui_config_get_button = gr.Button(refresh_symbol)\n",
        "            read_webui_config_button = gr.Button(\"è¯»å–\")\n",
        "        with gr.Row():\n",
        "            read_webui_config_dir = gr.Textbox(lines=1, label=\"è¯»å–ç›®å½•\", value=os.path.join(os.getcwd(),\"kohya_config_webui_save\") )  \n",
        "            read_webui_config_name = gr.Dropdown(choices=[], label=\"è¯»å–æ–‡ä»¶\", value=\"\" )          \n",
        "    with gr.Row():\n",
        "        write_files_button = gr.Button(\"ç”Ÿæˆtomlå‚æ•°ä¸é‡‡æ ·é…ç½®æ–‡ä»¶\")\n",
        "        all_parameter_get_button = gr.Button(\"å…¨éƒ¨å‚æ•°ç¡®è®¤\")\n",
        "        write_files_dir = gr.Textbox( lines=1, label=\"å†™å…¥æ–‡ä»¶å¤¹\", placeholder=\"ä¸€èˆ¬å¡«kohya_scriptç›®å½•ï¼Œç•™ç©ºå°±é»˜è®¤æ ¹ç›®å½•\", value=\"\" )\n",
        "    write_files_title = gr.Markdown(\"ç”Ÿæˆé€‚ç”¨äºkohya/train_network.pyçš„é…ç½®æ–‡ä»¶\")\n",
        "    with gr.Tabs():\n",
        "        with gr.TabItem(\"åŸºç¡€å‚æ•°\"):\n",
        "            common_parameter_get_button = gr.Button(\"ç¡®å®š\")\n",
        "            common_parameter_title = gr.Markdown(\"\")\n",
        "            with gr.Accordion(\"å½“å‰åŸºç¡€å‚æ•°é…ç½®\", open=False):\n",
        "                common_parameter_toml = gr.Textbox(label=\"tomlå½¢å¼\", placeholder=\"åŸºç¡€å‚æ•°\", value=\"\")\n",
        "            with gr.Row():\n",
        "                train_data_dir = gr.Textbox(lines=1, label=\"train_data_dir\", placeholder=\"è®­ç»ƒé›†è·¯å¾„\", value=\"\")\n",
        "            with gr.Accordion(\"ä½¿ç”¨æ­£åˆ™åŒ–(å¯é€‰)\", open=False):\n",
        "                with gr.Row():\n",
        "                    reg_data_dir = gr.Textbox(lines=1, label=\"reg_data_dir\", placeholder=\"æ­£åˆ™åŒ–é›†è·¯å¾„ï¼ˆå¡«å…¥æ„å‘³ç€å¯ç”¨æ­£åˆ™åŒ–ï¼‰\", value=\"\")\n",
        "                    prior_loss_weight = gr.Slider(0, 1, step=0.01, value=0.3, label=\"æ­£åˆ™åŒ–æƒé‡\")\n",
        "            with gr.Row():\n",
        "                base_model_dir = gr.Textbox(label=\"åº•æ¨¡æ–‡ä»¶å¤¹åœ°å€\", placeholder=\"æ–‡ä»¶å¤¹è·¯å¾„\", value=\"\")\n",
        "                base_model_name = gr.Dropdown(choices=[],label=\"åº•æ¨¡\",value=\"\")\n",
        "                base_model_get_button = gr.Button(refresh_symbol)\n",
        "            with gr.Accordion(\"ä½¿ç”¨vae(å¯é€‰)\", open=False):\n",
        "                with gr.Row():\n",
        "                    use_vae = gr.Checkbox(label=\"æ˜¯å¦ä½¿ç”¨vae\",value=False)\n",
        "                with gr.Row():\n",
        "                    vae_model_dir = gr.Textbox(label=\"vaeæ–‡ä»¶å¤¹åœ°å€\", placeholder=\"æ–‡ä»¶å¤¹è·¯å¾„\", value=\"\")\n",
        "                    vae_model_name = gr.Dropdown(choices=[],label=\"vae\", value=\"\")\n",
        "                    vae_model_get_button = gr.Button(refresh_symbol)\n",
        "            with gr.Row():\n",
        "                width = gr.Slider(64, 1920, step=64, value=512, label=\"è®­ç»ƒåˆ†è¾¨ç‡ï¼ˆå®½ï¼‰width\")\n",
        "                height = gr.Slider(64, 1920, step=64, value=512, label=\"è®­ç»ƒåˆ†è¾¨ç‡ï¼ˆé«˜ï¼‰height\")\n",
        "                batch_size = gr.Slider(1, 24, step=1, value=1, label=\"batchå¤§å°\")\n",
        "            with gr.Row():\n",
        "                noise_offset = gr.Slider(0, 1, step=0.01, value=0.05, label=\"noise_offset\")\n",
        "                keep_tokens = gr.Slider(0, 225, step=1, value=0, label=\"keep_tokens\")\n",
        "                min_snr_gamma = gr.Slider(0, 100, step=0.1, value=5, label=\"min_snr_gamma(è®¾ç½®ä¸º0åˆ™ä¸ç”Ÿæ•ˆ)\")\n",
        "            \"\"\"\n",
        "            with gr.Row():\n",
        "                gr.Markdown(\"repeat * å›¾ç‰‡æ•° = æ¯ä¸ªepochçš„stepsæ•°\")\n",
        "            \"\"\"\n",
        "            with gr.Row():\n",
        "                max_train_method = gr.Dropdown([\"max_train_epochs\",\"max_train_steps\"], label=\"ä»¥epochsæˆ–stepsæ¥æŒ‡å®šæœ€å¤§è®­ç»ƒæ—¶é—´\", value=\"max_train_epochs\")\n",
        "                max_train_value = gr.Number(label=\"æœ€å¤§è®­ç»ƒepochs\\stepsæ•°\", value=10, precision=0)\n",
        "            with gr.Accordion(\"è¾“å‡ºè®¾ç½®\", open=True):\n",
        "                with gr.Row():\n",
        "                    output_dir = gr.Textbox( label=\"æ¨¡å‹ã€logæ—¥å¿—è¾“å‡ºåœ°å€ï¼ˆè‡ªè¡Œä¿®æ”¹ï¼‰\", placeholder=\"æ–‡ä»¶å¤¹è·¯å¾„\",value=os.path.join(os.getcwd(),\"output\") )\n",
        "                    output_name = gr.Textbox(label=\"è¾“å‡ºæ¨¡å‹åç§°ï¼ˆè‡ªè¡Œä¿®æ”¹ï¼‰\", placeholder=\"åç§°\",value=\"output_name\")\n",
        "                    save_model_as = gr.Dropdown([\"safetensors\",\"ckpt\",\"pt\"], label=\"ä¿å­˜æ¨¡å‹æ ¼å¼\", value=\"safetensors\")\n",
        "                with gr.Row():\n",
        "                    save_every_n_epochs = gr.Slider(1, 499, step=1, value=1, label=\"æ¯nä¸ªepochä¿å­˜ä¸€æ¬¡\")\n",
        "                    save_n_epoch_ratio = gr.Slider(1, 499, step=1, value=0, label=\"ç­‰é—´éš”ä¿å­˜nä¸ª(å¦‚ä¸ä¸º0ï¼Œä¼šè¦†ç›–æ¯nä¸ªepochä¿å­˜ä¸€æ¬¡)\")\n",
        "                    save_last_n_epochs = gr.Slider(1, 499, step=1, value=499, label=\"æœ€å¤šä¿å­˜nä¸ªï¼ˆåé¢çš„å‡ºæ¥å°±ä¼šæŠŠå‰é¢åˆ äº†,ä¼˜å…ˆçº§æœ€é«˜ï¼‰\")\n",
        "                with gr.Row():   \n",
        "                    save_state = gr.Checkbox(label=\"ä¿å­˜å­¦ä¹ çŠ¶æ€\",value=False)\n",
        "            with gr.Row():\n",
        "                optimizer_type = gr.Dropdown([\"AdamW8bit\", \"Lion\", \"DAdaptation\", \"AdamW\", \"SGDNesterov\", \"SGDNesterov8bit\", \"AdaFactor\"],\\\n",
        "                                label=\"optimizer_typeä¼˜åŒ–å™¨ç±»å‹\", value=\"AdamW8bit\")\n",
        "                unet_lr = gr.Number(label=\"unetå­¦ä¹ ç‡\", value=1e-4)\n",
        "                text_encoder_lr = gr.Number(label=\"text_encoderå­¦ä¹ ç‡\", value=1e-5)\n",
        "            with gr.Row():\n",
        "                lr_scheduler = gr.Dropdown([\"cosine_with_restarts\",\"cosine\",\"polynomial\",\"linear\",\"constant_with_warmup\",\"constant\"],\\\n",
        "                               label=\"lr_schedulerå­¦ä¹ ç‡è°ƒåº¦å™¨\", value=\"cosine_with_restarts\")\n",
        "                lr_warmup_steps = gr.Number(label=\"å‡æ¸©æ­¥æ•°\", value=0, precision=0)\n",
        "                lr_restart_cycles = gr.Number(label=\"é€€ç«é‡å¯æ¬¡æ•°\", value=1, precision=0)\n",
        "            with gr.Row():\n",
        "                train_method = gr.Dropdown([\"LoRA-LierLa\", \"LoRA-C3Lier\",\\\n",
        "                                \"LoCon_Lycoris\",\"LoHa_Lycoris\",\\\n",
        "                                \"DyLoRa-LierLa\", \"DyLoRa-C3Lier\"],\\\n",
        "                                label=\"train_methodè®­ç»ƒæ–¹æ³•\", value=\"LoRA-LierLa\")\n",
        "                network_dim = gr.Number(label=\"çº¿æ€§dim\", value=32, precision=0)\n",
        "                network_alpha = gr.Number(label=\"çº¿æ€§alphaï¼ˆå¯ä»¥ä¸ºå°æ•°ï¼‰\", value=16)\n",
        "            with gr.Accordion(\"é¢å¤–ç½‘ç»œå‚æ•°(LoRA-C3Lierã€LoConã€LoHaã€DyLoRa-C3Lieréƒ½å±äºå·ç§¯,unitä¸ºDyLoRaä¸“ç”¨)\", open=True):\n",
        "                with gr.Row():\n",
        "                    with gr.Column():\n",
        "                        conv_dim = gr.Number(label=\"å·ç§¯dim\", info=\"ä½¿ç”¨DyLoRa-C3Lieræ—¶ä¼šè¢«è®¾ç½®ä¸ºç­‰äºåŸºç¡€dim\", value=8, precision=0)\n",
        "                    with gr.Column():\n",
        "                        conv_alpha = gr.Number(label=\"å·ç§¯alpha\", info=\"å¯ä»¥ä¸ºå°æ•°\", value=1)\n",
        "                    with gr.Column():\n",
        "                        unit = gr.Number(label=\"åˆ†å‰²å•ä½unit(æ•´æ•°)\", info=\"ä½¿ç”¨DyLoRaæ—¶ï¼Œè¯·è®©dimä¸ºunitçš„å€æ•°\", value=1, precision=0)\n",
        "            with gr.Row():          \n",
        "                v2 = gr.Checkbox(label=\"v2\")\n",
        "                v_parameterization = gr.Checkbox(label=\"v_parameterization\")\n",
        "                lowram = gr.Checkbox(label=\"lowram\")\n",
        "                xformers = gr.Checkbox(label=\"xformers\",value=True)\n",
        "                cache_latents = gr.Checkbox(label=\"cache_latents\",value=True)\n",
        "                shuffle_caption = gr.Checkbox(label=\"shuffle_caption\",value=True)\n",
        "                enable_bucket = gr.Checkbox(label=\"enable_bucket\",value=True)\n",
        "        with gr.TabItem(\"é‡‡æ ·å‚æ•°\"):\n",
        "            sample_parameter_get_button = gr.Button(\"ç¡®å®š\")\n",
        "            sample_parameter_title = gr.Markdown(\"\")\n",
        "            with gr.Accordion(\"å½“å‰é‡‡æ ·é…ç½®\", open=False):\n",
        "                sample_parameter_toml = gr.Textbox(label=\"tomlå½¢å¼\", placeholder=\"é‡‡æ ·é…ç½®\", value=\"\")\n",
        "            with gr.Row():\n",
        "                #enable_sample = gr.Checkbox(label=\"æ˜¯å¦å¯ç”¨é‡‡æ ·åŠŸèƒ½\")\n",
        "                sample_every_n_type = gr.Dropdown([\"sample_every_n_epochs\", \"sample_every_n_steps\"], label=\"sample_every_n_type\", value=\"sample_every_n_epochs\")\n",
        "                sample_every_n_type_value = gr.Number(label=\"sample_every_n_type_value\", value=1, precision=0)\n",
        "            with gr.Row():\n",
        "                sample_sampler = gr.Dropdown([\"ddim\", \"pndm\", \"lms\", \"euler\", \"euler_a\", \"heun\",\\\n",
        "                            \"dpm_2\", \"dpm_2_a\", \"dpmsolver\",\"dpmsolver++\", \"dpmsingle\",\\\n",
        "                            \"k_lms\", \"k_euler\", \"k_euler_a\", \"k_dpm_2\", \"k_dpm_2_a\"],\\\n",
        "                            label=\"é‡‡æ ·å™¨\", value=\"euler_a\")\n",
        "                sample_seed = gr.Number(label=\"é‡‡æ ·ç§å­(-1ä¸æ˜¯éšæœºï¼Œå¤§äº0æ‰ç”Ÿæ•ˆ)\", value=-1, precision=0)\n",
        "            with gr.Row():\n",
        "                sample_width = gr.Slider(64, 1920, step=64, value=512, label=\"é‡‡æ ·å›¾ç‰‡å®½\")\n",
        "                sample_height = gr.Slider(64, 1920, step=64, value=768, label=\"é‡‡æ ·å›¾ç‰‡é«˜\")\n",
        "                sample_scale = gr.Slider(1, 30, step=0.5, value=7, label=\"æç¤ºè¯ç›¸å…³æ€§\")\n",
        "                sample_steps = gr.Slider(1, 150, step=1, value=24, label=\"é‡‡æ ·è¿­ä»£æ­¥æ•°\")\n",
        "            with gr.Row():\n",
        "                prompt = gr.Textbox(lines=10, label=\"prompt\", placeholder=\"æ­£é¢æç¤ºè¯\", value=\"(masterpiece, best quality, hires:1.2), 1girl, solo,\")\n",
        "                default_negative = (\"(worst quality, bad quality:1.4), \"\n",
        "                          \"lowres, bad anatomy, bad hands, text, error, \"\n",
        "                          \"missing fingers, extra digit, fewer digits, \"\n",
        "                          \"cropped, worst quality, low quality, normal quality, \"\n",
        "                          \"jpeg artifacts,signature, watermark, username, blurry,\")\n",
        "                negative = gr.Textbox(lines=10, label=\"negative\", placeholder=\"è´Ÿé¢æç¤ºè¯\", value=default_negative)\n",
        "        with gr.TabItem(\"è¿›é˜¶å‚æ•°\"):\n",
        "            plus_parameter_get_button = gr.Button(\"ç¡®å®š\")\n",
        "            plus_parameter_title = gr.Markdown(\"\")\n",
        "            with gr.Accordion(\"å½“å‰è¿›é˜¶å‚æ•°é…ç½®\", open=False):\n",
        "                plus_parameter_toml = gr.Textbox(label=\"tomlå½¢å¼\", placeholder=\"è¿›é˜¶å‚æ•°\", value=\"\")\n",
        "            with gr.Row():\n",
        "                use_retrain = gr.Dropdown([\"no\",\"model\",\"state\"], label=\"æ˜¯å¦ä½¿ç”¨é‡è®­ç»ƒ\", value=\"no\")\n",
        "                retrain_dir = gr.Textbox(lines=1, label=\"é‡è®­ç»ƒè·¯å¾„\", placeholder=\"æ¨¡å‹æˆ–è€…çŠ¶æ€è·¯å¾„\", value=\"\")\n",
        "            with gr.Row():\n",
        "                min_bucket_reso = gr.Slider(64, 1920, step=64, value=256, label=\"æœ€ä½æ¡¶åˆ†è¾¨ç‡\")\n",
        "                max_bucket_reso = gr.Slider(64, 1920, step=64, value=1024, label=\"æœ€é«˜æ¡¶åˆ†è¾¨ç‡\")\n",
        "                clip_skip = gr.Slider(0, 25, step=1, value=2, label=\"è·³è¿‡å±‚æ•°\")\n",
        "                max_token_length = gr.Slider(75, 225, step=75, value=225, label=\"è®­ç»ƒæœ€å¤§tokenæ•°\")\n",
        "                caption_extension = gr.Textbox(lines=1, label=\"æ ‡ç­¾æ–‡ä»¶æ‰©å±•å\", placeholder=\"ä¸€èˆ¬å¡«.txtæˆ–.cap\", value=\".txt\")\n",
        "                seed = gr.Number(label=\"ç§å­\", value=1337, precision=0)\n",
        "            with gr.Row():\n",
        "                network_train_unet_only= gr.Checkbox(label=\"ä»…è®­ç»ƒunetç½‘ç»œ\",value=False)\n",
        "                network_train_text_encoder_only = gr.Checkbox(label=\"ä»…è®­ç»ƒtext_encoderç½‘ç»œ\",value=False)\n",
        "            with gr.Accordion(\"åˆ†å±‚å­¦ä¹ æ¨¡å—\", open=True):\n",
        "                gr.Markdown(\"å­¦ä¹ ç‡åˆ†å±‚ï¼Œä¸ºä¸åŒå±‚çš„ç»“æ„æŒ‡å®šä¸åŒå­¦ä¹ ç‡å€æ•°ï¼› å¦‚æœæŸä¸€å±‚æƒé‡ä¸º0ï¼Œé‚£è¯¥å±‚ä¸ä¼šè¢«åˆ›å»º\")\n",
        "                with gr.Row():\n",
        "                    with gr.Column(scale=15):\n",
        "                        up_lr_weight = gr.Textbox(lines=1, label=\"ä¸Šå±‚å­¦ä¹ ç‡æƒé‡\", placeholder=\"ç•™ç©ºåˆ™ä¸å¯ç”¨\",\\\n",
        "                                      info=\"15å±‚ï¼Œä¾‹å¦‚1.5,1.5,1.5,1.5,1.0,1.0,1.0,1.0,0.5,0.5,0.5,0.5\", value=\"\")\n",
        "                    with gr.Column(scale=1):\n",
        "                        mid_lr_weight = gr.Textbox(lines=1, label=\"ä¸­å±‚å­¦ä¹ ç‡æƒé‡\", placeholder=\"ç•™ç©ºåˆ™ä¸å¯ç”¨\",\\\n",
        "                                      info=\"1å±‚ï¼Œä¾‹å¦‚2.0\", value=\"\")\n",
        "                    with gr.Column(scale=15):\n",
        "                        down_lr_weight = gr.Textbox(lines=1, label=\"ä¸‹å±‚å­¦ä¹ ç‡æƒé‡\", placeholder=\"ç•™ç©ºåˆ™ä¸å¯ç”¨\",\\\n",
        "                                      info=\"15å±‚ï¼Œä¾‹å¦‚0.5,0.5,0.5,0.5,1.0,1.0,1.0,1.0,1.5,1.5,1.5,1.5\", value=\"\")\n",
        "                gr.Markdown(\"dimå’Œalphaåˆ†å±‚ï¼Œä¸ºä¸åŒå±‚çš„ç»“æ„æŒ‡å®šä¸åŒçš„dimå’Œalphaï¼ˆ`DyLoRa`æ— æ³•ä½¿ç”¨ï¼Œå·ç§¯åˆ†å±‚åªæœ‰`LoRa-C3Lierã€LoConã€LoHa`å¯ä»¥ä½¿ç”¨ï¼‰\")\n",
        "                with gr.Row():\n",
        "                        block_dims = gr.Textbox(lines=1, label=\"çº¿æ€§dimåˆ†å±‚\", placeholder=\"ç•™ç©ºåˆ™ä¸å¯ç”¨\",\\\n",
        "                                      info=\"25å±‚ï¼ˆä¸Šä¸­ä¸‹ï¼‰ï¼Œä¾‹å¦‚2,4,4,4,8,8,8,8,12,12,12,12,16,12,12,12,12,8,8,8,8,4,4,4,2\", value=\"\")\n",
        "                        block_alphas = gr.Textbox(lines=1, label=\"çº¿æ€§alphaåˆ†å±‚\", placeholder=\"ç•™ç©ºåˆ™ä¸å¯ç”¨\",\\\n",
        "                                      info=\"25å±‚ï¼ˆä¸Šä¸­ä¸‹ï¼‰ï¼Œä¾‹å¦‚2,2,2,2,4,4,4,4,6,6,6,6,8,6,6,6,6,4,4,4,4,2,2,2,2\", value=\"\")\n",
        "                with gr.Row():\n",
        "                        conv_block_dims = gr.Textbox(lines=1, label=\"å·ç§¯dimåˆ†å±‚\", placeholder=\"ç•™ç©ºåˆ™ä¸å¯ç”¨\",\\\n",
        "                                        info=\"25å±‚ï¼ˆä¸Šä¸­ä¸‹ï¼‰ï¼Œä¾‹å¦‚2,2,2,2,4,4,4,4,6,6,6,6,8,6,6,6,6,4,4,4,4,2,2,2,2\", value=\"\")\n",
        "                        conv_block_alphas = gr.Textbox(lines=1, label=\"å·ç§¯alphaåˆ†å±‚\", placeholder=\"ç•™ç©ºåˆ™ä¸å¯ç”¨\",\\\n",
        "                                        info=\"25å±‚ï¼ˆä¸Šä¸­ä¸‹ï¼‰ï¼Œä¾‹å¦‚2,2,2,2,4,4,4,4,6,6,6,6,8,6,6,6,6,4,4,4,4,2,2,2,2\", value=\"\")\n",
        "\n",
        "\n",
        "    def dict_key_list_2_list(dict_key_list):\n",
        "        list = []\n",
        "        for key in dict_key_list:\n",
        "            try:\n",
        "                list.append(globals()[key])\n",
        "            except KeyError:\n",
        "                print(f\"Error: parameter_dict_key_listä¸­{key}ä¸å­˜åœ¨\")\n",
        "        list_len = len(list)\n",
        "        return list, list_len\n",
        "\n",
        "    common_parameter_dict_key_list = [\"train_data_dir\",\n",
        "                      \"reg_data_dir\",\n",
        "                      \"prior_loss_weight\",\n",
        "                      \"base_model_dir\",\n",
        "                      \"base_model_name\",\n",
        "                      \"use_vae\",\n",
        "                      \"vae_model_dir\",\n",
        "                      \"vae_model_name\",\n",
        "                      \"width\",\n",
        "                      \"height\",\n",
        "                      \"batch_size\",\n",
        "                      \"noise_offset\",\n",
        "                      \"keep_tokens\",\n",
        "                      \"min_snr_gamma\",\n",
        "                      \"max_train_method\",\n",
        "                      \"max_train_value\",\n",
        "                      \"output_dir\",\n",
        "                      \"output_name\",\n",
        "                      \"save_model_as\",\n",
        "                      \"save_every_n_epochs\",\n",
        "                      \"save_n_epoch_ratio\",\n",
        "                      \"save_last_n_epochs\",\n",
        "                      \"save_state\",\n",
        "                      \"optimizer_type\",\n",
        "                      \"unet_lr\",\n",
        "                      \"text_encoder_lr\",\n",
        "                      \"lr_scheduler\",\n",
        "                      \"lr_warmup_steps\",\n",
        "                      \"lr_restart_cycles\",\n",
        "                      \"train_method\",\n",
        "                      \"network_dim\",\n",
        "                      \"network_alpha\",\n",
        "                      \"conv_dim\",\n",
        "                      \"conv_alpha\",\n",
        "                      \"unit\",\n",
        "                      \"v2\",\n",
        "                      \"v_parameterization\",\n",
        "                      \"lowram\",\n",
        "                      \"xformers\",\n",
        "                      \"cache_latents\",\n",
        "                      \"shuffle_caption\",\n",
        "                      \"enable_bucket\"]\n",
        "    common_parameter_list, parameter_len_dict[\"common\"] = dict_key_list_2_list(common_parameter_dict_key_list)\n",
        "    sample_parameter_dict_key_list = [\"sample_every_n_type\",\n",
        "                      \"sample_every_n_type_value\",\n",
        "                      \"sample_sampler\",\n",
        "                      \"sample_seed\",\n",
        "                      \"sample_width\",\n",
        "                      \"sample_height\",\n",
        "                      \"sample_scale\",\n",
        "                      \"sample_steps\",\n",
        "                      \"prompt\",\n",
        "                      \"negative\"]\n",
        "    sample_parameter_list, parameter_len_dict[\"sample\"] = dict_key_list_2_list(sample_parameter_dict_key_list)\n",
        "    plus_parameter_dict_key_list = [\"use_retrain\",\n",
        "                    \"retrain_dir\",\n",
        "                    \"min_bucket_reso\",\n",
        "                    \"max_bucket_reso\",\n",
        "                    \"clip_skip\",\n",
        "                    \"max_token_length\",\n",
        "                    \"caption_extension\",\n",
        "                    \"seed\",\n",
        "                    \"network_train_unet_only\",\n",
        "                    \"network_train_text_encoder_only\",\n",
        "                    \"up_lr_weight\",\n",
        "                    \"mid_lr_weight\",\n",
        "                    \"down_lr_weight\",\n",
        "                    \"block_dims\",\n",
        "                    \"block_alphas\",\n",
        "                    \"conv_block_dims\",\n",
        "                    \"conv_block_alphas\"]\n",
        "    plus_parameter_list, parameter_len_dict[\"plus\"] = dict_key_list_2_list(plus_parameter_dict_key_list)\n",
        "\n",
        "    #æ³¨æ„ï¼Œè¿™å‡ ä¸ªlistç›¸åŠ çš„é¡ºåºä¸èƒ½é”™\n",
        "    all_parameter_list = common_parameter_list + sample_parameter_list + plus_parameter_list\n",
        "    all_parameter_dict_key_list = common_parameter_dict_key_list + sample_parameter_dict_key_list + plus_parameter_dict_key_list\n",
        "\n",
        "    save_webui_config_button.click(fn=save_webui_config,\n",
        "                    inputs=[save_webui_config_dir, save_webui_config_name, write_files_dir],\n",
        "                    outputs=save_read_webui_config_title      \n",
        "    )\n",
        "    read_webui_config_get_button.click(fn=read_webui_config_get,\n",
        "                      inputs=[read_webui_config_dir],\n",
        "                      outputs=[read_webui_config_name]       \n",
        "    )\n",
        "    read_webui_config_button.click(fn=read_webui_config,\n",
        "                    inputs=[read_webui_config_dir, read_webui_config_name, write_files_dir] + all_parameter_list,\n",
        "                    outputs=[save_read_webui_config_title, write_files_dir] + all_parameter_list\n",
        "    )\n",
        "    common_parameter_get_button.click(fn=common_parameter_get,\n",
        "                    inputs=common_parameter_list,\n",
        "                    outputs=[common_parameter_toml,  common_parameter_title]\n",
        "    )\n",
        "    sample_parameter_get_button.click(fn=sample_parameter_get,\n",
        "                    inputs=sample_parameter_list,\n",
        "                    outputs=[sample_parameter_toml,  sample_parameter_title]\n",
        "    )\n",
        "    plus_parameter_get_button.click(fn=plus_parameter_get,\n",
        "                    inputs=plus_parameter_list,\n",
        "                    outputs=[plus_parameter_toml,  plus_parameter_title]\n",
        "    )\n",
        "    all_parameter_get_button.click(fn=all_parameter_get,\n",
        "                    inputs=all_parameter_list,\n",
        "                    outputs=[common_parameter_toml, sample_parameter_toml, plus_parameter_toml,  write_files_title]\n",
        "    )\n",
        "    base_model_get_button.click(fn=model_get,\n",
        "                  inputs=[base_model_dir],\n",
        "                  outputs=[base_model_name]\n",
        "    )\n",
        "    vae_model_get_button.click(fn=model_get,\n",
        "                  inputs=[vae_model_dir],\n",
        "                  outputs=[vae_model_name]\n",
        "    )\n",
        "    write_files_button.click(fn=write_files,\n",
        "                inputs=[write_files_dir],\n",
        "                outputs=[write_files_title]\n",
        "    )\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(share=False,inbrowser=False,inline=True,debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNv6whrNjHPpxmgtHuC8ypu",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}